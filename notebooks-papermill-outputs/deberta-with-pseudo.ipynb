{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497fec48",
   "metadata": {
    "papermill": {
     "duration": 0.010826,
     "end_time": "2025-02-11T21:09:16.799668",
     "exception": false,
     "start_time": "2025-02-11T21:09:16.788842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training deberta-v3-large model to generate high quality pseudolabels\n",
    "\n",
    "Initially deberta-v3-large model raises OOM error. \n",
    "\n",
    "Optimized the training pipeline via Pytorch\n",
    "- Gradient accumulation\n",
    "- Gradient checkpoint\n",
    "- Using bfloat data types\n",
    "- Autocast\n",
    "\n",
    "1 fold (with 4-5 epochs) takes around ~5 hours, each epoch ~50 minutes. %87+ accuracy. (See notebook version 6)\n",
    "\n",
    "Another approach would be to use [huggingface accelerator](https://huggingface.co/docs/accelerate/en/index) as it automates this process without the need to customize manually as well as distribution of training while using multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba2d54",
   "metadata": {
    "papermill": {
     "duration": 0.008974,
     "end_time": "2025-02-11T21:09:16.818940",
     "exception": false,
     "start_time": "2025-02-11T21:09:16.809966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Deberta-v3-large?\n",
    "![Comparison of BERT variants in 2025](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/modernbert/modernbert_pareto_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcde85a",
   "metadata": {
    "papermill": {
     "duration": 0.010251,
     "end_time": "2025-02-11T21:09:16.960112",
     "exception": false,
     "start_time": "2025-02-11T21:09:16.949861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3feccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:16.979664Z",
     "iopub.status.busy": "2025-02-11T21:09:16.979374Z",
     "iopub.status.idle": "2025-02-11T21:09:16.991717Z",
     "shell.execute_reply": "2025-02-11T21:09:16.990956Z"
    },
    "papermill": {
     "duration": 0.023262,
     "end_time": "2025-02-11T21:09:16.992736",
     "exception": false,
     "start_time": "2025-02-11T21:09:16.969474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed folder: tokenizer\n",
      "Removed file: train.log\n",
      "Removed file: config.pth\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os, shutil\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.path.dirname(os.getcwd()), 'deberta-v3-large-finetuned-with-pseudolabels/')\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "for item in os.listdir(OUTPUT_DIR):\n",
    "    item_path = os.path.join(OUTPUT_DIR, item)\n",
    "    if os.path.isfile(item_path):  # If it's a file, remove it\n",
    "        os.remove(item_path)\n",
    "        print(f\"Removed file: {item}\")\n",
    "    elif os.path.isdir(item_path):  # If it's a directory, remove it\n",
    "        shutil.rmtree(item_path)\n",
    "        print(f\"Removed folder: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece157a0",
   "metadata": {
    "papermill": {
     "duration": 0.009547,
     "end_time": "2025-02-11T21:09:17.014777",
     "exception": false,
     "start_time": "2025-02-11T21:09:17.005230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b91ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:17.056933Z",
     "iopub.status.busy": "2025-02-11T21:09:17.056726Z",
     "iopub.status.idle": "2025-02-11T21:09:30.301491Z",
     "shell.execute_reply": "2025-02-11T21:09:30.300495Z"
    },
    "papermill": {
     "duration": 13.25935,
     "end_time": "2025-02-11T21:09:30.302688",
     "exception": false,
     "start_time": "2025-02-11T21:09:17.043338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.48.3\n",
      "Uninstalling transformers-4.48.3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully uninstalled transformers-4.48.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tokenizer as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from tokenizers) (0.28.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.21.0\n",
      "transformers.__version__: 4.48.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('python -m pip install transformers>=4.48.0')\n",
    "os.system('pip uninstall -y tokenizer')\n",
    "os.system('python -m pip install tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de7cc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:30.567151Z",
     "iopub.status.busy": "2025-02-11T21:09:30.565730Z",
     "iopub.status.idle": "2025-02-11T21:09:31.381413Z",
     "shell.execute_reply": "2025-02-11T21:09:31.380172Z"
    },
    "papermill": {
     "duration": 0.959317,
     "end_time": "2025-02-11T21:09:31.383045",
     "exception": false,
     "start_time": "2025-02-11T21:09:30.423728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=True\n",
    "    competition='NBME'\n",
    "    _wandb_kernel='zehra'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    # model=\"/kaggle/input/deberta-v3-large/pytorch/0501/1\" # if running on Kaggle, use this path \n",
    "    model = \"/workspace/deberta-v3-large\" # if running on local machine, use this path  \n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=1 #0.05\n",
    "    num_warmup_steps=0\n",
    "    epochs=5\n",
    "    encoder_lr = 1e-5 #encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size = 12 #batch_size=16\n",
    "    fc_dropout=0.2\n",
    "    max_len=512\n",
    "    weight_decay=0.1 #0.01\n",
    "    gradient_accumulation_steps=2 #1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    CFG.trn_fold = [0]\n",
    "\n",
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b35291f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:31.409595Z",
     "iopub.status.busy": "2025-02-11T21:09:31.409029Z",
     "iopub.status.idle": "2025-02-11T21:09:37.394129Z",
     "shell.execute_reply": "2025-02-11T21:09:37.393369Z"
    },
    "papermill": {
     "duration": 6.001726,
     "end_time": "2025-02-11T21:09:37.395975",
     "exception": false,
     "start_time": "2025-02-11T21:09:31.394249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to use your W&B account, create a .env file in the parent folder and provide your W&B access token as WANDB_API_KEY. \n",
      "Get your W&B access token from here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-628529071760834444\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - Waiting for wandb.init()...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ Waiting for wandb.init()...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | Waiting for wandb.init()...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: / Waiting for wandb.init()...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - Waiting for wandb.init()...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20250211_210932-kl09y3t4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/workspace/deberta-v3-large\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public/runs/kl09y3t4?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb: local notebook login\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    \n",
    "    import wandb\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    # Load environment variables from .env file in the parent folder\n",
    "    load_dotenv(os.path.join(os.path.dirname(os.getcwd()), '.env'))\n",
    "\n",
    "    secret_value_0 = os.getenv(\"WANDB_API_KEY\")\n",
    "    if secret_value_0:\n",
    "        wandb.login(key=secret_value_0)\n",
    "        anony = None\n",
    "    else:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, create a .env file in the parent folder and provide your W&B access token as WANDB_API_KEY. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='NBME-Public', \n",
    "                     name=CFG.model,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=CFG.model,\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1330f0ab",
   "metadata": {
    "papermill": {
     "duration": 0.014461,
     "end_time": "2025-02-11T21:09:37.425210",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.410749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f53c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:37.451590Z",
     "iopub.status.busy": "2025-02-11T21:09:37.451367Z",
     "iopub.status.idle": "2025-02-11T21:09:37.457714Z",
     "shell.execute_reply": "2025-02-11T21:09:37.457032Z"
    },
    "papermill": {
     "duration": 0.018087,
     "end_time": "2025-02-11T21:09:37.458664",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.440577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecef9e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:37.480401Z",
     "iopub.status.busy": "2025-02-11T21:09:37.480192Z",
     "iopub.status.idle": "2025-02-11T21:09:37.490172Z",
     "shell.execute_reply": "2025-02-11T21:09:37.489587Z"
    },
    "papermill": {
     "duration": 0.021587,
     "end_time": "2025-02-11T21:09:37.491225",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.469638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## UPDATED FOR HANDLING NONEs in THE PSEUDOLABELS / only including confident inferences\n",
    "import ast\n",
    "\n",
    "# Update the create_labels_for_scoring function\n",
    "def create_labels_for_scoring(df):\n",
    "    # Initialize the 'location_for_create_labels' column with empty lists\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst and lst != '':  # Check if lst is not None or empty\n",
    "            # Ensure lst is a list of strings\n",
    "            if isinstance(lst, str):\n",
    "                lst = [lst]\n",
    "            elif isinstance(lst, list):\n",
    "                lst = [str(item) for item in lst]\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "\n",
    "    # Create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    \n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a4d3f",
   "metadata": {
    "papermill": {
     "duration": 0.009182,
     "end_time": "2025-02-11T21:09:37.515128",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.505946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda16310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:37.539376Z",
     "iopub.status.busy": "2025-02-11T21:09:37.539189Z",
     "iopub.status.idle": "2025-02-11T21:09:37.546603Z",
     "shell.execute_reply": "2025-02-11T21:09:37.545969Z"
    },
    "papermill": {
     "duration": 0.019812,
     "end_time": "2025-02-11T21:09:37.547648",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.527836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce168330",
   "metadata": {
    "papermill": {
     "duration": 0.010393,
     "end_time": "2025-02-11T21:09:37.568801",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.558408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08303cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:37.589222Z",
     "iopub.status.busy": "2025-02-11T21:09:37.588992Z",
     "iopub.status.idle": "2025-02-11T21:09:38.165042Z",
     "shell.execute_reply": "2025-02-11T21:09:38.164368Z"
    },
    "papermill": {
     "duration": 0.587576,
     "end_time": "2025-02-11T21:09:38.166020",
     "exception": false,
     "start_time": "2025-02-11T21:09:37.578444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (14300, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (143, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_notes.shape: (42146, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('/workspace/data/train.csv')\n",
    "train['annotation'] = train['annotation'].apply(ast.literal_eval)\n",
    "train['location'] = train['location'].apply(ast.literal_eval)\n",
    "features = pd.read_csv('/workspace/data/features.csv')\n",
    "def preprocess_features(features):\n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "features = preprocess_features(features)\n",
    "patient_notes = pd.read_csv('/workspace/data/patient_notes.csv')\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4868ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:38.190586Z",
     "iopub.status.busy": "2025-02-11T21:09:38.190366Z",
     "iopub.status.idle": "2025-02-11T21:09:38.207381Z",
     "shell.execute_reply": "2025-02-11T21:09:38.206879Z"
    },
    "papermill": {
     "duration": 0.030056,
     "end_time": "2025-02-11T21:09:38.208947",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.178891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>95333_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>912</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>95333_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>913</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>95333_914</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>914</td>\n",
       "      <td>[photobia]</td>\n",
       "      <td>[274 282]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>95333_915</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>915</td>\n",
       "      <td>[no sick contacts]</td>\n",
       "      <td>[421 437]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>95333_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>916</td>\n",
       "      <td>[Subjective fever]</td>\n",
       "      <td>[314 330]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14300 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  case_num  pn_num  feature_num                              annotation          location  annotation_length\n",
       "0      00016_000         0      16            0          [dad with recent heart attcak]         [696 724]                  1\n",
       "1      00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                  1\n",
       "2      00016_002         0      16            2                        [chest pressure]         [203 217]                  1\n",
       "3      00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                  2\n",
       "4      00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                  1\n",
       "...          ...       ...     ...          ...                                     ...               ...                ...\n",
       "14295  95333_912         9   95333          912                                      []                []                  0\n",
       "14296  95333_913         9   95333          913                                      []                []                  0\n",
       "14297  95333_914         9   95333          914                              [photobia]         [274 282]                  1\n",
       "14298  95333_915         9   95333          915                      [no sick contacts]         [421 437]                  1\n",
       "14299  95333_916         9   95333          916                      [Subjective fever]         [314 330]                  1\n",
       "\n",
       "[14300 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['annotation_length'] = train['annotation'].apply(len) # refers to number of annotation\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c01c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:38.234830Z",
     "iopub.status.busy": "2025-02-11T21:09:38.234616Z",
     "iopub.status.idle": "2025-02-11T21:09:38.630830Z",
     "shell.execute_reply": "2025-02-11T21:09:38.630248Z"
    },
    "papermill": {
     "duration": 0.408451,
     "end_time": "2025-02-11T21:09:38.631785",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.223334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>fold</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000_006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[521 526]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001_004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[179 195]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001_006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[347 353]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001_007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[220 235]</td>\n",
       "      <td>Shortness-of-breath</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001_011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[1 5]</td>\n",
       "      <td>17-year</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122512</th>\n",
       "      <td>95331_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>[283 302, 401 421]</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122513</th>\n",
       "      <td>95331_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "      <td>[8 9]</td>\n",
       "      <td>Female</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122516</th>\n",
       "      <td>95332_906</td>\n",
       "      <td>9</td>\n",
       "      <td>95332</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>[319 327]</td>\n",
       "      <td>Vomiting</td>\n",
       "      <td>Ms. Madden is a 20yo female who presents with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122518</th>\n",
       "      <td>95334_901</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>[13 18]</td>\n",
       "      <td>20-year</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122519</th>\n",
       "      <td>95334_904</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>[41 49, 136 143]</td>\n",
       "      <td>Global-headache-OR-diffuse-headache</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86232 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  case_num  pn_num  feature_num  fold            location                         feature_text                                         pn_history\n",
       "0       00000_006         0       0            6     1           [521 526]                         Adderall-use  17-year-old male, has come to the student heal...\n",
       "1       00001_004         0       1            4     1           [179 195]                          Lightheaded  17 yo male with recurrent palpitations for the...\n",
       "2       00001_006         0       1            6     1           [347 353]                         Adderall-use  17 yo male with recurrent palpitations for the...\n",
       "3       00001_007         0       1            7     1           [220 235]                  Shortness-of-breath  17 yo male with recurrent palpitations for the...\n",
       "4       00001_011         0       1           11     1               [1 5]                              17-year  17 yo male with recurrent palpitations for the...\n",
       "...           ...       ...     ...          ...   ...                 ...                                  ...                                                ...\n",
       "122512  95331_912         9   95331          912     1  [283 302, 401 421]          Family-history-of-migraines  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "122513  95331_913         9   95331          913     1               [8 9]                               Female  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "122516  95332_906         9   95332          906     1           [319 327]                             Vomiting  Ms. Madden is a 20yo female who presents with ...\n",
       "122518  95334_901         9   95334          901     1             [13 18]                              20-year  patient is a 20 yo F who presents with a heada...\n",
       "122519  95334_904         9   95334          904     1    [41 49, 136 143]  Global-headache-OR-diffuse-headache  patient is a 20 yo F who presents with a heada...\n",
       "\n",
       "[86232 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels = pd.read_csv('/workspace/data/pseudolabels.csv')\n",
    "pseudolabels =  pseudolabels.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "pseudolabels = pseudolabels.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "\n",
    "pseudolabels = pseudolabels.dropna(subset=['location'])\n",
    "pseudolabels = pseudolabels[pseudolabels['location'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "def convert_location_format(location):\n",
    "    if pd.isna(location) or not location:\n",
    "        return []\n",
    "    if isinstance(location, str):\n",
    "        return [loc.strip() for loc in location.split(';')]\n",
    "    return location\n",
    "\n",
    "pseudolabels['location'] = pseudolabels['location'].apply(convert_location_format)\n",
    "\n",
    "pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b7c8204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:38.656180Z",
     "iopub.status.busy": "2025-02-11T21:09:38.656005Z",
     "iopub.status.idle": "2025-02-11T21:09:38.679812Z",
     "shell.execute_reply": "2025-02-11T21:09:38.679329Z"
    },
    "papermill": {
     "duration": 0.036319,
     "end_time": "2025-02-11T21:09:38.680552",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.644233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudolabels['annotation_length'] = pseudolabels['location'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6234544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:38.701601Z",
     "iopub.status.busy": "2025-02-11T21:09:38.701442Z",
     "iopub.status.idle": "2025-02-11T21:09:38.709803Z",
     "shell.execute_reply": "2025-02-11T21:09:38.709387Z"
    },
    "papermill": {
     "duration": 0.020144,
     "end_time": "2025-02-11T21:09:38.710559",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.690415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>fold</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000_006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[521 526]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001_004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[179 195]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001_006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[347 353]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001_007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[220 235]</td>\n",
       "      <td>Shortness-of-breath</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001_011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[1 5]</td>\n",
       "      <td>17-year</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122512</th>\n",
       "      <td>95331_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>[283 302, 401 421]</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122513</th>\n",
       "      <td>95331_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "      <td>[8 9]</td>\n",
       "      <td>Female</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122516</th>\n",
       "      <td>95332_906</td>\n",
       "      <td>9</td>\n",
       "      <td>95332</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>[319 327]</td>\n",
       "      <td>Vomiting</td>\n",
       "      <td>Ms. Madden is a 20yo female who presents with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122518</th>\n",
       "      <td>95334_901</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>[13 18]</td>\n",
       "      <td>20-year</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122519</th>\n",
       "      <td>95334_904</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>[41 49, 136 143]</td>\n",
       "      <td>Global-headache-OR-diffuse-headache</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86232 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  case_num  pn_num  feature_num  fold            location                         feature_text                                         pn_history  annotation_length\n",
       "0       00000_006         0       0            6     1           [521 526]                         Adderall-use  17-year-old male, has come to the student heal...                  1\n",
       "1       00001_004         0       1            4     1           [179 195]                          Lightheaded  17 yo male with recurrent palpitations for the...                  1\n",
       "2       00001_006         0       1            6     1           [347 353]                         Adderall-use  17 yo male with recurrent palpitations for the...                  1\n",
       "3       00001_007         0       1            7     1           [220 235]                  Shortness-of-breath  17 yo male with recurrent palpitations for the...                  1\n",
       "4       00001_011         0       1           11     1               [1 5]                              17-year  17 yo male with recurrent palpitations for the...                  1\n",
       "...           ...       ...     ...          ...   ...                 ...                                  ...                                                ...                ...\n",
       "122512  95331_912         9   95331          912     1  [283 302, 401 421]          Family-history-of-migraines  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...                  2\n",
       "122513  95331_913         9   95331          913     1               [8 9]                               Female  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...                  1\n",
       "122516  95332_906         9   95332          906     1           [319 327]                             Vomiting  Ms. Madden is a 20yo female who presents with ...                  1\n",
       "122518  95334_901         9   95334          901     1             [13 18]                              20-year  patient is a 20 yo F who presents with a heada...                  1\n",
       "122519  95334_904         9   95334          904     1    [41 49, 136 143]  Global-headache-OR-diffuse-headache  patient is a 20 yo F who presents with a heada...                  2\n",
       "\n",
       "[86232 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78d1dbd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:38.849390Z",
     "iopub.status.busy": "2025-02-11T21:09:38.849191Z",
     "iopub.status.idle": "2025-02-11T21:09:38.857101Z",
     "shell.execute_reply": "2025-02-11T21:09:38.856474Z"
    },
    "papermill": {
     "duration": 0.137166,
     "end_time": "2025-02-11T21:09:38.858054",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.720888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pseudolabels\n",
    "# drop fold column\n",
    "train = train.drop(columns=['fold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a7a25",
   "metadata": {
    "papermill": {
     "duration": 0.012,
     "end_time": "2025-02-11T21:09:38.886648",
     "exception": false,
     "start_time": "2025-02-11T21:09:38.874648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f574d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:39.022780Z",
     "iopub.status.busy": "2025-02-11T21:09:39.022274Z",
     "iopub.status.idle": "2025-02-11T21:09:39.135974Z",
     "shell.execute_reply": "2025-02-11T21:09:39.135239Z"
    },
    "papermill": {
     "duration": 0.12816,
     "end_time": "2025-02-11T21:09:39.137041",
     "exception": false,
     "start_time": "2025-02-11T21:09:39.008881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    17247\n",
       "1    17247\n",
       "2    17246\n",
       "3    17246\n",
       "4    17246\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d180b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:39.184485Z",
     "iopub.status.busy": "2025-02-11T21:09:39.184260Z",
     "iopub.status.idle": "2025-02-11T21:09:39.188510Z",
     "shell.execute_reply": "2025-02-11T21:09:39.187761Z"
    },
    "papermill": {
     "duration": 0.017694,
     "end_time": "2025-02-11T21:09:39.189509",
     "exception": false,
     "start_time": "2025-02-11T21:09:39.171815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    display(train.groupby('fold').size())\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71646b9",
   "metadata": {
    "papermill": {
     "duration": 0.011775,
     "end_time": "2025-02-11T21:09:39.334418",
     "exception": false,
     "start_time": "2025-02-11T21:09:39.322643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab63eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:39.464445Z",
     "iopub.status.busy": "2025-02-11T21:09:39.463935Z",
     "iopub.status.idle": "2025-02-11T21:09:57.850618Z",
     "shell.execute_reply": "2025-02-11T21:09:57.849741Z"
    },
    "papermill": {
     "duration": 18.399707,
     "end_time": "2025-02-11T21:09:57.851761",
     "exception": false,
     "start_time": "2025-02-11T21:09:39.452054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/42146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 196/42146 [00:00<00:21, 1956.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 456/42146 [00:00<00:17, 2330.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 691/42146 [00:00<00:17, 2337.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 965/42146 [00:00<00:16, 2491.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 1231/42146 [00:00<00:16, 2550.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|â–Ž         | 1499/42146 [00:00<00:15, 2592.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|â–         | 1782/42146 [00:00<00:15, 2669.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|â–         | 2049/42146 [00:00<00:15, 2661.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|â–Œ         | 2323/42146 [00:00<00:14, 2683.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|â–Œ         | 2592/42146 [00:01<00:15, 2561.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 2850/42146 [00:01<00:15, 2459.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|â–‹         | 3098/42146 [00:01<00:16, 2409.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|â–Š         | 3340/42146 [00:01<00:16, 2324.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|â–Š         | 3574/42146 [00:01<00:17, 2256.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|â–‰         | 3801/42146 [00:01<00:17, 2207.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|â–‰         | 4023/42146 [00:01<00:17, 2168.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|â–ˆ         | 4241/42146 [00:01<00:18, 2055.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|â–ˆ         | 4448/42146 [00:01<00:18, 2033.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|â–ˆ         | 4652/42146 [00:02<00:18, 2018.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|â–ˆâ–        | 4855/42146 [00:02<00:18, 2018.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|â–ˆâ–        | 5058/42146 [00:02<00:18, 1968.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|â–ˆâ–Ž        | 5269/42146 [00:02<00:18, 2008.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|â–ˆâ–Ž        | 5486/42146 [00:02<00:17, 2053.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|â–ˆâ–Ž        | 5707/42146 [00:02<00:17, 2096.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|â–ˆâ–        | 5940/42146 [00:02<00:16, 2162.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|â–ˆâ–        | 6177/42146 [00:02<00:16, 2223.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|â–ˆâ–Œ        | 6411/42146 [00:02<00:15, 2255.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|â–ˆâ–Œ        | 6646/42146 [00:02<00:15, 2283.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|â–ˆâ–‹        | 6882/42146 [00:03<00:15, 2305.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|â–ˆâ–‹        | 7114/42146 [00:03<00:15, 2309.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|â–ˆâ–‹        | 7346/42146 [00:03<00:15, 2305.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|â–ˆâ–Š        | 7577/42146 [00:03<00:15, 2302.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|â–ˆâ–Š        | 7809/42146 [00:03<00:14, 2306.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|â–ˆâ–‰        | 8041/42146 [00:03<00:14, 2309.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|â–ˆâ–‰        | 8272/42146 [00:03<00:14, 2296.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|â–ˆâ–ˆ        | 8502/42146 [00:03<00:14, 2294.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|â–ˆâ–ˆ        | 8732/42146 [00:03<00:14, 2292.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|â–ˆâ–ˆâ–       | 8962/42146 [00:03<00:14, 2244.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|â–ˆâ–ˆâ–       | 9187/42146 [00:04<00:14, 2221.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|â–ˆâ–ˆâ–       | 9414/42146 [00:04<00:14, 2235.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|â–ˆâ–ˆâ–Ž       | 9645/42146 [00:04<00:14, 2256.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|â–ˆâ–ˆâ–Ž       | 9885/42146 [00:04<00:14, 2297.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|â–ˆâ–ˆâ–       | 10130/42146 [00:04<00:13, 2342.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|â–ˆâ–ˆâ–       | 10370/42146 [00:04<00:13, 2359.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|â–ˆâ–ˆâ–Œ       | 10607/42146 [00:04<00:13, 2320.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|â–ˆâ–ˆâ–Œ       | 10840/42146 [00:04<00:14, 2196.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|â–ˆâ–ˆâ–‹       | 11066/42146 [00:04<00:14, 2213.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|â–ˆâ–ˆâ–‹       | 11293/42146 [00:04<00:13, 2227.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|â–ˆâ–ˆâ–‹       | 11529/42146 [00:05<00:13, 2265.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|â–ˆâ–ˆâ–Š       | 11767/42146 [00:05<00:13, 2296.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|â–ˆâ–ˆâ–Š       | 12004/42146 [00:05<00:13, 2316.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|â–ˆâ–ˆâ–‰       | 12242/42146 [00:05<00:12, 2332.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|â–ˆâ–ˆâ–‰       | 12476/42146 [00:05<00:12, 2332.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|â–ˆâ–ˆâ–ˆ       | 12710/42146 [00:05<00:12, 2331.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|â–ˆâ–ˆâ–ˆ       | 12946/42146 [00:05<00:12, 2339.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 13181/42146 [00:05<00:12, 2325.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 13414/42146 [00:05<00:12, 2302.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 13649/42146 [00:05<00:12, 2313.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 13881/42146 [00:06<00:12, 2315.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 14115/42146 [00:06<00:12, 2320.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 14348/42146 [00:06<00:11, 2321.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 14581/42146 [00:06<00:11, 2321.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14814/42146 [00:06<00:11, 2315.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15046/42146 [00:06<00:11, 2288.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 15275/42146 [00:06<00:11, 2281.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 15504/42146 [00:06<00:11, 2280.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 15733/42146 [00:06<00:11, 2255.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15959/42146 [00:06<00:11, 2240.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 16184/42146 [00:07<00:11, 2198.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 16404/42146 [00:07<00:11, 2194.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 16624/42146 [00:07<00:11, 2186.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 16843/42146 [00:07<00:11, 2174.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17065/42146 [00:07<00:11, 2187.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 17287/42146 [00:07<00:11, 2194.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 17514/42146 [00:07<00:11, 2214.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 17736/42146 [00:07<00:11, 2205.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17961/42146 [00:07<00:10, 2217.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18188/42146 [00:08<00:10, 2230.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 18412/42146 [00:08<00:10, 2227.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18635/42146 [00:08<00:10, 2224.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 18860/42146 [00:08<00:10, 2230.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19084/42146 [00:08<00:10, 2209.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 19306/42146 [00:08<00:10, 2201.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 19529/42146 [00:08<00:10, 2207.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 19756/42146 [00:08<00:10, 2224.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 19979/42146 [00:08<00:09, 2221.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20208/42146 [00:08<00:09, 2240.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 20448/42146 [00:09<00:09, 2286.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 20700/42146 [00:09<00:09, 2354.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 20950/42146 [00:09<00:08, 2394.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21200/42146 [00:09<00:08, 2425.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 21446/42146 [00:09<00:08, 2432.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 21690/42146 [00:09<00:08, 2409.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 21934/42146 [00:09<00:08, 2416.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 22176/42146 [00:09<00:08, 2408.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 22418/42146 [00:09<00:08, 2410.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22661/42146 [00:09<00:08, 2414.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 22903/42146 [00:10<00:07, 2411.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23148/42146 [00:10<00:07, 2421.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 23393/42146 [00:10<00:07, 2427.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 23641/42146 [00:10<00:07, 2442.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 23886/42146 [00:10<00:07, 2439.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 24130/42146 [00:10<00:07, 2438.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 24374/42146 [00:10<00:07, 2427.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 24617/42146 [00:10<00:07, 2414.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 24861/42146 [00:10<00:07, 2419.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 25107/42146 [00:10<00:07, 2430.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 25351/42146 [00:11<00:06, 2420.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 25597/42146 [00:11<00:06, 2432.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 25841/42146 [00:11<00:06, 2427.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26084/42146 [00:11<00:06, 2426.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 26328/42146 [00:11<00:06, 2428.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 26571/42146 [00:11<00:06, 2339.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 26811/42146 [00:11<00:06, 2355.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27056/42146 [00:11<00:06, 2382.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27295/42146 [00:11<00:06, 2380.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 27535/42146 [00:11<00:06, 2383.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 27777/42146 [00:12<00:06, 2392.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28017/42146 [00:12<00:06, 2352.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 28253/42146 [00:12<00:05, 2339.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 28488/42146 [00:12<00:05, 2312.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 28725/42146 [00:12<00:05, 2328.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 28958/42146 [00:12<00:05, 2268.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29186/42146 [00:12<00:05, 2240.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 29411/42146 [00:12<00:05, 2225.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 29634/42146 [00:12<00:05, 2219.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 29857/42146 [00:12<00:05, 2209.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30079/42146 [00:13<00:05, 2207.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30300/42146 [00:13<00:05, 2199.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 30522/42146 [00:13<00:05, 2202.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 30743/42146 [00:13<00:05, 2198.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 30963/42146 [00:13<00:05, 2194.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 31183/42146 [00:13<00:04, 2195.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 31403/42146 [00:13<00:04, 2193.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 31626/42146 [00:13<00:04, 2203.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 31849/42146 [00:13<00:04, 2210.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 32071/42146 [00:13<00:04, 2192.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 32291/42146 [00:14<00:04, 2185.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 32512/42146 [00:14<00:04, 2189.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 32731/42146 [00:14<00:04, 2179.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 32949/42146 [00:14<00:04, 2161.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 33166/42146 [00:14<00:04, 2140.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 33381/42146 [00:14<00:04, 2105.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 33592/42146 [00:14<00:04, 2087.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 33801/42146 [00:14<00:04, 2081.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 34010/42146 [00:14<00:03, 2082.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 34221/42146 [00:15<00:03, 2088.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 34430/42146 [00:15<00:03, 2084.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 34639/42146 [00:15<00:03, 2078.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 34847/42146 [00:15<00:03, 2075.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 35055/42146 [00:15<00:03, 2066.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 35264/42146 [00:15<00:03, 2072.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 35472/42146 [00:15<00:03, 2064.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 35682/42146 [00:15<00:03, 2073.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 35904/42146 [00:15<00:02, 2115.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 36121/42146 [00:15<00:02, 2128.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 36334/42146 [00:16<00:02, 2128.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 36555/42146 [00:16<00:02, 2152.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 36786/42146 [00:16<00:02, 2198.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 37011/42146 [00:16<00:02, 2213.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 37283/42146 [00:16<00:02, 2364.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 37549/42146 [00:16<00:01, 2452.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 37829/42146 [00:16<00:01, 2555.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38106/42146 [00:16<00:01, 2618.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 38368/42146 [00:16<00:01, 2605.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 38638/42146 [00:16<00:01, 2630.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 38907/42146 [00:17<00:01, 2646.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 39173/42146 [00:17<00:01, 2650.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 39439/42146 [00:17<00:01, 2606.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 39700/42146 [00:17<00:00, 2580.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 39959/42146 [00:17<00:00, 2579.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 40218/42146 [00:17<00:00, 2572.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 40476/42146 [00:17<00:00, 2544.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 40731/42146 [00:17<00:00, 2520.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 40984/42146 [00:17<00:00, 2411.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 41227/42146 [00:17<00:00, 2338.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 41462/42146 [00:18<00:00, 2325.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 41696/42146 [00:18<00:00, 2328.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 41936/42146 [00:18<00:00, 2347.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42146/42146 [00:18<00:00, 2296.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pn_history max(lengths): 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:00<00:00, 16462.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_text max(lengths): 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 354\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "for text_col in ['pn_history']:\n",
    "    pn_history_lengths = []\n",
    "    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        pn_history_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n",
    "\n",
    "for text_col in ['feature_text']:\n",
    "    features_lengths = []\n",
    "    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        features_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n",
    "\n",
    "CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61bf15bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:57.892890Z",
     "iopub.status.busy": "2025-02-11T21:09:57.892679Z",
     "iopub.status.idle": "2025-02-11T21:09:57.903796Z",
     "shell.execute_reply": "2025-02-11T21:09:57.903140Z"
    },
    "papermill": {
     "duration": 0.030899,
     "end_time": "2025-02-11T21:09:57.904734",
     "exception": false,
     "start_time": "2025-02-11T21:09:57.873835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text, feature_text):\n",
    "\n",
    "    # Omit token_type_ids for ModernBERT\n",
    "    is_token_type_ids = CFG.model != 'answerdotai/ModernBERT-base'\n",
    "\n",
    "    inputs = cfg.tokenizer(text, feature_text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False,\n",
    "                           return_token_type_ids=is_token_type_ids)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation_length, location_list):\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "    if annotation_length != 0:\n",
    "        for location in location_list:\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start_idx = -1\n",
    "                end_idx = -1\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                for idx in range(len(offset_mapping)):\n",
    "                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                        start_idx = idx - 1\n",
    "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                        end_idx = idx + 1\n",
    "                if start_idx == -1:\n",
    "                    start_idx = end_idx\n",
    "                if (start_idx != -1) & (end_idx != -1):\n",
    "                    label[start_idx:end_idx] = 1\n",
    "    return torch.tensor(label, dtype=torch.bfloat16)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.feature_texts = df['feature_text'].values\n",
    "        self.pn_historys = df['pn_history'].values\n",
    "        self.annotation_lengths = df['annotation_length'].values\n",
    "        self.locations = df['location'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.pn_historys[item], \n",
    "                               self.feature_texts[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.pn_historys[item], \n",
    "                             self.annotation_lengths[item], \n",
    "                             self.locations[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064d499",
   "metadata": {
    "papermill": {
     "duration": 0.018044,
     "end_time": "2025-02-11T21:09:57.941733",
     "exception": false,
     "start_time": "2025-02-11T21:09:57.923689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f79235e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:57.979783Z",
     "iopub.status.busy": "2025-02-11T21:09:57.979520Z",
     "iopub.status.idle": "2025-02-11T21:09:57.989608Z",
     "shell.execute_reply": "2025-02-11T21:09:57.988705Z"
    },
    "papermill": {
     "duration": 0.030465,
     "end_time": "2025-02-11T21:09:57.990713",
     "exception": false,
     "start_time": "2025-02-11T21:09:57.960248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        # Debugging input shapes and types\n",
    "        #print(\"Feature extraction inputs:\")\n",
    "        #for k, v in inputs.items():\n",
    "            #print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "        \n",
    "        # Process the inputs through the model\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Debugging the output of the model\n",
    "        #print(f\"Last hidden states: shape={last_hidden_states.shape}, dtype={last_hidden_states.dtype}\")\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Debugging the forward pass\n",
    "        #print(\"Starting forward pass...\")\n",
    "        #print(\"Input keys and shapes:\")\n",
    "        #for k, v in inputs.items():\n",
    "            #print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):  # Enable AMP\n",
    "            #print(\"Running model under AMP...\")\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Debugging model output\n",
    "        #print(\"Model outputs:\")\n",
    "        #if isinstance(outputs, tuple):\n",
    "           # for idx, output in enumerate(outputs):\n",
    "                #print(f\"Output {idx}: shape={output.shape if hasattr(output, 'shape') else 'N/A'}\")\n",
    "        #else:\n",
    "            #print(f\"Outputs: {outputs}\")\n",
    "            #pass\n",
    "        \n",
    "        # Final linear layer\n",
    "        feature = outputs.last_hidden_state\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        \n",
    "        # Debugging final output\n",
    "        #print(f\"Final output shape: {output.shape}, dtype={output.dtype}\")\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ea60c",
   "metadata": {
    "papermill": {
     "duration": 0.01798,
     "end_time": "2025-02-11T21:09:58.030046",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.012066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22de68e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:58.069710Z",
     "iopub.status.busy": "2025-02-11T21:09:58.069480Z",
     "iopub.status.idle": "2025-02-11T21:09:58.077264Z",
     "shell.execute_reply": "2025-02-11T21:09:58.076514Z"
    },
    "papermill": {
     "duration": 0.029654,
     "end_time": "2025-02-11T21:09:58.078416",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.048762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7270e916a690>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98fb1e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:58.120191Z",
     "iopub.status.busy": "2025-02-11T21:09:58.120017Z",
     "iopub.status.idle": "2025-02-11T21:09:58.131720Z",
     "shell.execute_reply": "2025-02-11T21:09:58.131025Z"
    },
    "papermill": {
     "duration": 0.032397,
     "end_time": "2025-02-11T21:09:58.132720",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.100323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Validation function with detailed debugging for intermediate outputs.\n",
    "    \"\"\"\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"Starting validation...\")\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        # Move inputs and labels to the correct device\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)  # Model predictions\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # Store predictions\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Debugging: Log step-wise progress and intermediate outputs\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "            #print(f\"Sample Predictions: {y_preds.sigmoid()[:5].view(-1).tolist()}\")  # Example predictions\n",
    "            #print(f\"Sample Labels: {labels[:5].view(-1).tolist()}\")  # Example labels\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "\n",
    "    # Debugging: Check shape and content of predictions\n",
    "    #print(f\"Validation Predictions Shape: {predictions.shape}\")\n",
    "    # print(f\"First 5 Predictions: {predictions[:5]}\")\n",
    "\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"\n",
    "    Training function with detailed debugging for loss and gradients.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting training epoch {epoch + 1} for fold {fold}\")\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the correct device\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        # Mixed precision training\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex, dtype=torch.bfloat16):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "            loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "\n",
    "        # Gradient accumulation\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print(f'Epoch: [{epoch+1}][{step}/{len(train_loader)}] '\n",
    "                  f'Elapsed {timeSince(start, float(step+1)/len(train_loader))} '\n",
    "                  f'Loss: {losses.val:.4f}({losses.avg:.4f}) '\n",
    "                  f'Grad Norm: {grad_norm:.4f}  '\n",
    "                  f'LR: {scheduler.get_lr()[0]}')\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed. Average loss: {losses.avg:.4f}\")\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30848bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:58.175546Z",
     "iopub.status.busy": "2025-02-11T21:09:58.175382Z",
     "iopub.status.idle": "2025-02-11T21:09:58.187441Z",
     "shell.execute_reply": "2025-02-11T21:09:58.186758Z"
    },
    "papermill": {
     "duration": 0.034953,
     "end_time": "2025-02-11T21:09:58.188479",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.153526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['pn_history'].values\n",
    "    valid_labels = create_labels_for_scoring(valid_folds)\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "\n",
    "    checkpoint_path = f\"/workspace/deberta-v3-large-5-folds-public/deberta-v3-large_fold{fold}_best.pth\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        LOGGER.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=\"cuda\", weights_only=False) # need to use weight_only = True for latest pytorch version\n",
    "        model.load_state_dict(checkpoint['model'], strict=False)  # Load model weights\n",
    "        model.to(device)\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "    else:\n",
    "        LOGGER.info(\"No checkpoint found, starting fresh.\")\n",
    "        \n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    best_score = 0.\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        print(\"Starting training\")\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        print(\"Starting evaluation\")\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n",
    "        \n",
    "        # scoring\n",
    "        char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score <= score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "            \n",
    "\n",
    "    #predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             #map_location=torch.device('cpu'))['predictions']\n",
    "    predictions = torch.load(OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'),weights_only=False)['predictions']\n",
    "\n",
    "    \n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b7d858b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:58.229183Z",
     "iopub.status.busy": "2025-02-11T21:09:58.229004Z",
     "iopub.status.idle": "2025-02-11T21:09:58.945932Z",
     "shell.execute_reply": "2025-02-11T21:09:58.944728Z"
    },
    "papermill": {
     "duration": 0.737634,
     "end_time": "2025-02-11T21:09:58.947757",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.210123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=True\n",
    "    competition='NBME'\n",
    "    _wandb_kernel='zehra'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    #model=\"microsoft/deberta-v3-large\" #\"answerdotai/ModernBERT-base\"\n",
    "    # model=\"/kaggle/input/deberta-v3-large/pytorch/0501/1\" If running on Kaggle\n",
    "    model = \"/workspace/deberta-v3-large\" # running on runpod instance\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.05\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr = 1e-5 #encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size = 10 #batch_size=16\n",
    "    fc_dropout=0.2\n",
    "    max_len=354\n",
    "    weight_decay=0.1 #0.01\n",
    "    gradient_accumulation_steps=1 #1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    CFG.trn_fold = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46cdbb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:58.991369Z",
     "iopub.status.busy": "2025-02-11T21:09:58.991038Z",
     "iopub.status.idle": "2025-02-11T21:09:58.995345Z",
     "shell.execute_reply": "2025-02-11T21:09:58.994516Z"
    },
    "papermill": {
     "duration": 0.025221,
     "end_time": "2025-02-11T21:09:58.996354",
     "exception": false,
     "start_time": "2025-02-11T21:09:58.971133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc35d758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:59.035790Z",
     "iopub.status.busy": "2025-02-11T21:09:59.035530Z",
     "iopub.status.idle": "2025-02-11T21:09:59.041461Z",
     "shell.execute_reply": "2025-02-11T21:09:59.040686Z"
    },
    "papermill": {
     "duration": 0.026057,
     "end_time": "2025-02-11T21:09:59.042397",
     "exception": false,
     "start_time": "2025-02-11T21:09:59.016340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold_training(oof_df, fold):\n",
    "    \"\"\"\n",
    "    Helper function to run training for a specific fold.\n",
    "    Concatenates the out-of-fold predictions to oof_df.\n",
    "    \"\"\"\n",
    "    _oof_df = train_loop(train, fold)\n",
    "    oof_df = pd.concat([oof_df, _oof_df])\n",
    "    LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "    evaluate_results(_oof_df)  # Evaluate results after each fold\n",
    "    return oof_df\n",
    "\n",
    "def evaluate_results(oof_df):\n",
    "    \"\"\"\n",
    "    Function to handle the result evaluation, including scoring and logging.\n",
    "    \"\"\"\n",
    "    labels = create_labels_for_scoring(oof_df)\n",
    "    predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
    "    results = get_results(char_probs, th=0.5)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c121ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T21:09:59.081013Z",
     "iopub.status.busy": "2025-02-11T21:09:59.080794Z",
     "iopub.status.idle": "2025-02-12T03:41:22.346160Z",
     "shell.execute_reply": "2025-02-12T03:41:22.345305Z"
    },
    "papermill": {
     "duration": 23483.285613,
     "end_time": "2025-02-12T03:41:22.347531",
     "exception": false,
     "start_time": "2025-02-11T21:09:59.061918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /workspace/deberta-v3-large-5-folds-public/deberta-v3-large_fold0_best.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "\n",
      "Starting training epoch 1 for fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/6898] Elapsed 0m 2s (remain 298m 56s) Loss: 0.0122(0.0122) Grad Norm: 86587.5938  LR: 9.999999999675951e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/6898] Elapsed 1m 25s (remain 96m 26s) Loss: 0.0073(0.0063) Grad Norm: 41556.8477  LR: 9.99999669437843e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][200/6898] Elapsed 2m 49s (remain 94m 15s) Loss: 0.0104(0.0061) Grad Norm: 18553.5176  LR: 9.999986908109645e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][300/6898] Elapsed 4m 12s (remain 92m 15s) Loss: 0.0019(0.0059) Grad Norm: 8929.4521  LR: 9.999970640882282e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][400/6898] Elapsed 5m 35s (remain 90m 42s) Loss: 0.0016(0.0058) Grad Norm: 12893.6094  LR: 9.999947892717426e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][500/6898] Elapsed 6m 58s (remain 89m 2s) Loss: 0.0050(0.0057) Grad Norm: 12037.0732  LR: 9.999918663644563e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][600/6898] Elapsed 8m 20s (remain 87m 28s) Loss: 0.0009(0.0055) Grad Norm: 3438.8408  LR: 9.999882953701581e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][700/6898] Elapsed 9m 43s (remain 85m 57s) Loss: 0.0048(0.0053) Grad Norm: 56405.3438  LR: 9.999840762934764e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][800/6898] Elapsed 11m 6s (remain 84m 32s) Loss: 0.0010(0.0052) Grad Norm: 24389.8828  LR: 9.999792091398804e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][900/6898] Elapsed 12m 29s (remain 83m 11s) Loss: 0.0550(0.0053) Grad Norm: 56596.9062  LR: 9.999736939156785e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1000/6898] Elapsed 13m 53s (remain 81m 52s) Loss: 0.0096(0.0053) Grad Norm: 24598.0508  LR: 9.999675306280197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1100/6898] Elapsed 15m 17s (remain 80m 30s) Loss: 0.0038(0.0052) Grad Norm: 15923.2549  LR: 9.999607192848925e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1200/6898] Elapsed 16m 39s (remain 79m 0s) Loss: 0.0035(0.0051) Grad Norm: 134362.8438  LR: 9.999532598951263e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1300/6898] Elapsed 18m 2s (remain 77m 36s) Loss: 0.0000(0.0050) Grad Norm: 45.0808  LR: 9.999451524683896e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1400/6898] Elapsed 19m 24s (remain 76m 7s) Loss: 0.0018(0.0050) Grad Norm: 9286.2549  LR: 9.99936397015191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1500/6898] Elapsed 20m 47s (remain 74m 45s) Loss: 0.0017(0.0050) Grad Norm: 13822.4561  LR: 9.999269935468797e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1600/6898] Elapsed 22m 9s (remain 73m 20s) Loss: 0.0001(0.0049) Grad Norm: 276.9291  LR: 9.999169420756443e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1700/6898] Elapsed 23m 31s (remain 71m 51s) Loss: 0.0006(0.0049) Grad Norm: 5518.7627  LR: 9.999062426145132e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1800/6898] Elapsed 24m 52s (remain 70m 23s) Loss: 0.0037(0.0048) Grad Norm: 56807.0117  LR: 9.998948951773553e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1900/6898] Elapsed 26m 14s (remain 68m 58s) Loss: 0.0001(0.0048) Grad Norm: 711.6124  LR: 9.99882899778879e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2000/6898] Elapsed 27m 37s (remain 67m 35s) Loss: 0.0077(0.0047) Grad Norm: 47745.2852  LR: 9.998702564346325e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2100/6898] Elapsed 28m 57s (remain 66m 6s) Loss: 0.0005(0.0047) Grad Norm: 7888.9331  LR: 9.998569651610042e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2200/6898] Elapsed 30m 21s (remain 64m 46s) Loss: 0.0167(0.0047) Grad Norm: 225400.1719  LR: 9.998430259752222e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2300/6898] Elapsed 31m 44s (remain 63m 24s) Loss: 0.0001(0.0046) Grad Norm: 1181.3639  LR: 9.998284388953545e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2400/6898] Elapsed 33m 8s (remain 62m 4s) Loss: 0.0014(0.0046) Grad Norm: 25478.0234  LR: 9.998132039403086e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2500/6898] Elapsed 34m 34s (remain 60m 47s) Loss: 0.0113(0.0046) Grad Norm: 136653.5938  LR: 9.997973211298323e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2600/6898] Elapsed 36m 0s (remain 59m 28s) Loss: 0.0040(0.0046) Grad Norm: 27859.6562  LR: 9.997807904845123e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2700/6898] Elapsed 37m 24s (remain 58m 7s) Loss: 0.0060(0.0046) Grad Norm: 41644.1797  LR: 9.997636120257758e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2800/6898] Elapsed 38m 48s (remain 56m 45s) Loss: 0.0029(0.0046) Grad Norm: 14699.1406  LR: 9.997457857758896e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2900/6898] Elapsed 40m 11s (remain 55m 22s) Loss: 0.0083(0.0045) Grad Norm: 32292.1719  LR: 9.997273117579597e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3000/6898] Elapsed 41m 35s (remain 54m 0s) Loss: 0.0029(0.0045) Grad Norm: 41150.0078  LR: 9.997081899959324e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3100/6898] Elapsed 43m 0s (remain 52m 39s) Loss: 0.0079(0.0044) Grad Norm: 116875.3906  LR: 9.996884205145929e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3200/6898] Elapsed 44m 23s (remain 51m 16s) Loss: 0.0002(0.0044) Grad Norm: 4114.8677  LR: 9.996680033395664e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3300/6898] Elapsed 45m 48s (remain 49m 54s) Loss: 0.0002(0.0044) Grad Norm: 5128.7695  LR: 9.996469384973175e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3400/6898] Elapsed 47m 13s (remain 48m 33s) Loss: 0.0059(0.0044) Grad Norm: 169769.7812  LR: 9.996252260151506e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3500/6898] Elapsed 48m 37s (remain 47m 10s) Loss: 0.0013(0.0044) Grad Norm: 14936.5488  LR: 9.996028659212089e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3600/6898] Elapsed 50m 0s (remain 45m 47s) Loss: 0.0062(0.0043) Grad Norm: 186536.6562  LR: 9.995798582444759e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3700/6898] Elapsed 51m 21s (remain 44m 22s) Loss: 0.0113(0.0043) Grad Norm: 88859.5078  LR: 9.995562030147736e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3800/6898] Elapsed 52m 43s (remain 42m 57s) Loss: 0.0029(0.0043) Grad Norm: 19515.4316  LR: 9.995319002627643e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3900/6898] Elapsed 54m 6s (remain 41m 34s) Loss: 0.0023(0.0043) Grad Norm: 104090.4766  LR: 9.995069500199487e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4000/6898] Elapsed 55m 30s (remain 40m 11s) Loss: 0.0013(0.0043) Grad Norm: 35112.8242  LR: 9.994813523186671e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4100/6898] Elapsed 56m 56s (remain 38m 50s) Loss: 0.0001(0.0043) Grad Norm: 2260.3567  LR: 9.994551071920995e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4200/6898] Elapsed 58m 21s (remain 37m 28s) Loss: 0.0013(0.0042) Grad Norm: 44056.3750  LR: 9.994282146742643e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4300/6898] Elapsed 59m 43s (remain 36m 3s) Loss: 0.0008(0.0042) Grad Norm: 52513.2539  LR: 9.994006748000197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4400/6898] Elapsed 61m 6s (remain 34m 40s) Loss: 0.0031(0.0042) Grad Norm: 78973.4531  LR: 9.99372487605063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4500/6898] Elapsed 62m 30s (remain 33m 17s) Loss: 0.0057(0.0042) Grad Norm: 48939.0352  LR: 9.993436531259297e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4600/6898] Elapsed 63m 53s (remain 31m 53s) Loss: 0.0070(0.0042) Grad Norm: 88278.2500  LR: 9.993141713999955e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4700/6898] Elapsed 65m 16s (remain 30m 30s) Loss: 0.0027(0.0041) Grad Norm: 65571.8984  LR: 9.99284042465474e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4800/6898] Elapsed 66m 40s (remain 29m 7s) Loss: 0.0004(0.0041) Grad Norm: 16867.7715  LR: 9.992532663614185e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4900/6898] Elapsed 68m 5s (remain 27m 44s) Loss: 0.0031(0.0041) Grad Norm: 97865.3672  LR: 9.992218431277205e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5000/6898] Elapsed 69m 30s (remain 26m 21s) Loss: 0.0016(0.0041) Grad Norm: 50496.3438  LR: 9.99189772805111e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5100/6898] Elapsed 70m 52s (remain 24m 57s) Loss: 0.0008(0.0041) Grad Norm: 35016.1328  LR: 9.991570554351592e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5200/6898] Elapsed 72m 16s (remain 23m 34s) Loss: 0.0050(0.0041) Grad Norm: 178412.3438  LR: 9.991236910602735e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5300/6898] Elapsed 73m 38s (remain 22m 11s) Loss: 0.0022(0.0041) Grad Norm: 454662.8750  LR: 9.990896797237002e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5400/6898] Elapsed 75m 0s (remain 20m 47s) Loss: 0.0075(0.0041) Grad Norm: 142693.1250  LR: 9.990550214695248e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5500/6898] Elapsed 76m 24s (remain 19m 24s) Loss: 0.0024(0.0040) Grad Norm: 68486.9688  LR: 9.990197163426711e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5600/6898] Elapsed 77m 49s (remain 18m 1s) Loss: 0.0055(0.0040) Grad Norm: 66398.2109  LR: 9.989837643889015e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5700/6898] Elapsed 79m 10s (remain 16m 37s) Loss: 0.0000(0.0040) Grad Norm: 1325.4532  LR: 9.989471656548169e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5800/6898] Elapsed 80m 33s (remain 15m 14s) Loss: 0.0007(0.0040) Grad Norm: 29074.1660  LR: 9.989099201878561e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5900/6898] Elapsed 81m 56s (remain 13m 50s) Loss: 0.0062(0.0040) Grad Norm: 167666.2969  LR: 9.988720280362967e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6000/6898] Elapsed 83m 20s (remain 12m 27s) Loss: 0.0007(0.0040) Grad Norm: 27633.9395  LR: 9.988334892492542e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6100/6898] Elapsed 84m 45s (remain 11m 4s) Loss: 0.0006(0.0040) Grad Norm: 214395.8594  LR: 9.987943038766825e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6200/6898] Elapsed 86m 8s (remain 9m 40s) Loss: 0.0060(0.0040) Grad Norm: 754284.6250  LR: 9.987544719693735e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6300/6898] Elapsed 87m 34s (remain 8m 17s) Loss: 0.0015(0.0039) Grad Norm: 202696.6406  LR: 9.987139935789569e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6400/6898] Elapsed 88m 57s (remain 6m 54s) Loss: 0.0014(0.0039) Grad Norm: 197421.1562  LR: 9.986728687579009e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6500/6898] Elapsed 90m 22s (remain 5m 31s) Loss: 0.0022(0.0039) Grad Norm: 64534.4219  LR: 9.986310975595112e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6600/6898] Elapsed 91m 47s (remain 4m 7s) Loss: 0.0000(0.0039) Grad Norm: 1094.6815  LR: 9.985886800379311e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6700/6898] Elapsed 93m 13s (remain 2m 44s) Loss: 0.0004(0.0039) Grad Norm: 69333.4844  LR: 9.985456162481427e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6800/6898] Elapsed 94m 39s (remain 1m 21s) Loss: 0.0002(0.0039) Grad Norm: 13813.5957  LR: 9.985019062459642e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][6897/6898] Elapsed 96m 1s (remain 0m 0s) Loss: 0.0012(0.0039) Grad Norm: 57039.5547  LR: 9.984588901738089e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average loss: 0.0039\n",
      "Starting evaluation\n",
      "Starting validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1725] Elapsed 0m 0s (remain 13m 38s) Loss: 0.0018(0.0018) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [100/1725] Elapsed 0m 7s (remain 1m 53s) Loss: 0.0010(0.0030) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [200/1725] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0019(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [300/1725] Elapsed 0m 20s (remain 1m 35s) Loss: 0.0022(0.0032) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [400/1725] Elapsed 0m 26s (remain 1m 28s) Loss: 0.0002(0.0033) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [500/1725] Elapsed 0m 33s (remain 1m 21s) Loss: 0.0053(0.0031) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [600/1725] Elapsed 0m 40s (remain 1m 14s) Loss: 0.0011(0.0031) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [700/1725] Elapsed 0m 46s (remain 1m 8s) Loss: 0.0105(0.0030) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [800/1725] Elapsed 0m 53s (remain 1m 1s) Loss: 0.0069(0.0033) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [900/1725] Elapsed 0m 59s (remain 0m 54s) Loss: 0.0081(0.0035) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1000/1725] Elapsed 1m 6s (remain 0m 48s) Loss: 0.0043(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1100/1725] Elapsed 1m 13s (remain 0m 41s) Loss: 0.0074(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1200/1725] Elapsed 1m 19s (remain 0m 34s) Loss: 0.0038(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1300/1725] Elapsed 1m 26s (remain 0m 28s) Loss: 0.0030(0.0039) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1400/1725] Elapsed 1m 33s (remain 0m 21s) Loss: 0.0023(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1500/1725] Elapsed 1m 39s (remain 0m 14s) Loss: 0.0022(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1600/1725] Elapsed 1m 46s (remain 0m 8s) Loss: 0.0050(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1700/1725] Elapsed 1m 53s (remain 0m 1s) Loss: 0.0005(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1724/1725] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0038(0.0035) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.0039  avg_val_loss: 0.0035  time: 5887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Score: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Save Best Score: 0.9780 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "\n",
      "Starting training epoch 2 for fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/6898] Elapsed 0m 1s (remain 172m 0s) Loss: 0.0016(0.0016) Grad Norm: 15739.0996  LR: 9.984584435431668e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][100/6898] Elapsed 1m 25s (remain 95m 36s) Loss: 0.0006(0.0028) Grad Norm: 7361.9819  LR: 9.984134542084126e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][200/6898] Elapsed 2m 47s (remain 93m 3s) Loss: 0.0091(0.0029) Grad Norm: 23621.1348  LR: 9.983678188325765e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][300/6898] Elapsed 4m 11s (remain 91m 49s) Loss: 0.0015(0.0027) Grad Norm: 30424.5098  LR: 9.98321537474811e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][400/6898] Elapsed 5m 34s (remain 90m 23s) Loss: 0.0000(0.0028) Grad Norm: 28.8889  LR: 9.982746101951055e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][500/6898] Elapsed 6m 57s (remain 88m 47s) Loss: 0.0023(0.0029) Grad Norm: 14682.8359  LR: 9.982270370542873e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][600/6898] Elapsed 8m 22s (remain 87m 46s) Loss: 0.0039(0.0030) Grad Norm: 8693.3545  LR: 9.9817881811402e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][700/6898] Elapsed 9m 48s (remain 86m 46s) Loss: 0.0035(0.0033) Grad Norm: 10553.2012  LR: 9.98129953436805e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][800/6898] Elapsed 11m 16s (remain 85m 49s) Loss: 0.0053(0.0032) Grad Norm: 29442.2266  LR: 9.980804430859802e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][900/6898] Elapsed 12m 41s (remain 84m 26s) Loss: 0.0005(0.0032) Grad Norm: 9363.5391  LR: 9.980302871257212e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1000/6898] Elapsed 14m 5s (remain 83m 1s) Loss: 0.0001(0.0031) Grad Norm: 462.4041  LR: 9.979794856210396e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1100/6898] Elapsed 15m 30s (remain 81m 38s) Loss: 0.0019(0.0032) Grad Norm: 29524.7793  LR: 9.979280386377841e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1200/6898] Elapsed 16m 54s (remain 80m 14s) Loss: 0.0001(0.0032) Grad Norm: 557.3111  LR: 9.978759462426399e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1300/6898] Elapsed 18m 20s (remain 78m 53s) Loss: 0.0031(0.0032) Grad Norm: 15798.3799  LR: 9.97823208503129e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1400/6898] Elapsed 19m 44s (remain 77m 27s) Loss: 0.0019(0.0032) Grad Norm: 10185.0000  LR: 9.977698254876099e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1500/6898] Elapsed 21m 7s (remain 75m 56s) Loss: 0.0001(0.0032) Grad Norm: 1475.0183  LR: 9.977157972652774e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1600/6898] Elapsed 22m 29s (remain 74m 24s) Loss: 0.0039(0.0032) Grad Norm: 9529.6992  LR: 9.976611239061623e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1700/6898] Elapsed 23m 50s (remain 72m 51s) Loss: 0.0024(0.0031) Grad Norm: 13157.7324  LR: 9.976058054811323e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1800/6898] Elapsed 25m 11s (remain 71m 18s) Loss: 0.0002(0.0031) Grad Norm: 3552.2886  LR: 9.975498420618907e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][1900/6898] Elapsed 26m 35s (remain 69m 54s) Loss: 0.0072(0.0031) Grad Norm: 25261.6094  LR: 9.97493233720977e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2000/6898] Elapsed 27m 59s (remain 68m 31s) Loss: 0.0019(0.0031) Grad Norm: 28776.6074  LR: 9.974359805317669e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2100/6898] Elapsed 29m 24s (remain 67m 9s) Loss: 0.0060(0.0031) Grad Norm: 71333.0078  LR: 9.973780825684713e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2200/6898] Elapsed 30m 49s (remain 65m 47s) Loss: 0.0009(0.0031) Grad Norm: 5952.8799  LR: 9.973195399061376e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2300/6898] Elapsed 32m 13s (remain 64m 22s) Loss: 0.0025(0.0031) Grad Norm: 11155.5371  LR: 9.972603526206484e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2400/6898] Elapsed 33m 34s (remain 62m 53s) Loss: 0.0124(0.0031) Grad Norm: 132462.9844  LR: 9.972005207887219e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2500/6898] Elapsed 34m 57s (remain 61m 27s) Loss: 0.0041(0.0031) Grad Norm: 36515.3359  LR: 9.97140044487912e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2600/6898] Elapsed 36m 20s (remain 60m 2s) Loss: 0.0048(0.0031) Grad Norm: 23800.5723  LR: 9.970789237966076e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2700/6898] Elapsed 37m 44s (remain 58m 38s) Loss: 0.0019(0.0031) Grad Norm: 17059.5859  LR: 9.970171587940331e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2800/6898] Elapsed 39m 8s (remain 57m 15s) Loss: 0.0182(0.0031) Grad Norm: 96675.6562  LR: 9.96954749560248e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2900/6898] Elapsed 40m 33s (remain 55m 52s) Loss: 0.0018(0.0030) Grad Norm: 12847.9014  LR: 9.968916961761469e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3000/6898] Elapsed 41m 58s (remain 54m 30s) Loss: 0.0211(0.0030) Grad Norm: 54947.9648  LR: 9.968279987234591e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3100/6898] Elapsed 43m 21s (remain 53m 4s) Loss: 0.0007(0.0030) Grad Norm: 18056.9668  LR: 9.96763657284749e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3200/6898] Elapsed 44m 45s (remain 51m 41s) Loss: 0.0051(0.0030) Grad Norm: 37590.4141  LR: 9.966986719434159e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3300/6898] Elapsed 46m 6s (remain 50m 14s) Loss: 0.0044(0.0030) Grad Norm: 27633.6816  LR: 9.966330427836933e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3400/6898] Elapsed 47m 29s (remain 48m 50s) Loss: 0.0000(0.0030) Grad Norm: 165.0560  LR: 9.965667698906493e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3500/6898] Elapsed 48m 54s (remain 47m 27s) Loss: 0.0119(0.0030) Grad Norm: 79650.1016  LR: 9.964998533501867e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3600/6898] Elapsed 50m 18s (remain 46m 3s) Loss: 0.0000(0.0030) Grad Norm: 757.8278  LR: 9.964322932490422e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3700/6898] Elapsed 51m 42s (remain 44m 40s) Loss: 0.0014(0.0030) Grad Norm: 10565.2793  LR: 9.96364089674787e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3800/6898] Elapsed 53m 6s (remain 43m 16s) Loss: 0.0036(0.0030) Grad Norm: 54933.2031  LR: 9.962952427158263e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][3900/6898] Elapsed 54m 30s (remain 41m 52s) Loss: 0.0018(0.0030) Grad Norm: 25147.0664  LR: 9.96225752461399e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4000/6898] Elapsed 55m 54s (remain 40m 28s) Loss: 0.0216(0.0030) Grad Norm: 340749.8750  LR: 9.961556190015781e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4100/6898] Elapsed 57m 17s (remain 39m 4s) Loss: 0.0019(0.0030) Grad Norm: 52425.2383  LR: 9.960848424272704e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4200/6898] Elapsed 58m 41s (remain 37m 40s) Loss: 0.0049(0.0030) Grad Norm: 132162.4844  LR: 9.960134228302158e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4300/6898] Elapsed 60m 5s (remain 36m 17s) Loss: 0.0001(0.0030) Grad Norm: 4356.5059  LR: 9.959413603029884e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4400/6898] Elapsed 61m 30s (remain 34m 53s) Loss: 0.0002(0.0030) Grad Norm: 10596.3271  LR: 9.95868654938995e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4500/6898] Elapsed 62m 54s (remain 33m 29s) Loss: 0.0004(0.0030) Grad Norm: 13535.7861  LR: 9.957953068324762e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4600/6898] Elapsed 64m 17s (remain 32m 5s) Loss: 0.0006(0.0030) Grad Norm: 29291.6836  LR: 9.957213160785053e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4700/6898] Elapsed 65m 41s (remain 30m 41s) Loss: 0.0004(0.0030) Grad Norm: 14574.2607  LR: 9.956466827729889e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4800/6898] Elapsed 67m 3s (remain 29m 17s) Loss: 0.0006(0.0030) Grad Norm: 62806.8594  LR: 9.955714070126663e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][4900/6898] Elapsed 68m 27s (remain 27m 53s) Loss: 0.0027(0.0029) Grad Norm: 42552.3086  LR: 9.954954888951093e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5000/6898] Elapsed 69m 50s (remain 26m 29s) Loss: 0.0015(0.0029) Grad Norm: 73717.7578  LR: 9.954189285187228e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5100/6898] Elapsed 71m 14s (remain 25m 5s) Loss: 0.0000(0.0029) Grad Norm: 73.7413  LR: 9.95341725982744e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5200/6898] Elapsed 72m 39s (remain 23m 42s) Loss: 0.0000(0.0029) Grad Norm: 1452.3430  LR: 9.952638813872425e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5300/6898] Elapsed 74m 1s (remain 22m 18s) Loss: 0.0087(0.0029) Grad Norm: 195889.7344  LR: 9.951853948331198e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5400/6898] Elapsed 75m 26s (remain 20m 54s) Loss: 0.0000(0.0029) Grad Norm: 1107.0168  LR: 9.951062664221102e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5500/6898] Elapsed 76m 51s (remain 19m 31s) Loss: 0.0011(0.0029) Grad Norm: 143217.1719  LR: 9.950264962567792e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5600/6898] Elapsed 78m 14s (remain 18m 7s) Loss: 0.0103(0.0029) Grad Norm: 55533.3281  LR: 9.949460844405247e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5700/6898] Elapsed 79m 34s (remain 16m 42s) Loss: 0.0001(0.0029) Grad Norm: 15888.4561  LR: 9.94865031077576e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5800/6898] Elapsed 80m 55s (remain 15m 18s) Loss: 0.0027(0.0029) Grad Norm: 100782.0156  LR: 9.947833362729942e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5900/6898] Elapsed 82m 16s (remain 13m 53s) Loss: 0.0008(0.0029) Grad Norm: 50762.7969  LR: 9.947010001326718e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6000/6898] Elapsed 83m 37s (remain 12m 29s) Loss: 0.0004(0.0029) Grad Norm: 70907.6406  LR: 9.946180227633322e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6100/6898] Elapsed 85m 0s (remain 11m 6s) Loss: 0.0001(0.0029) Grad Norm: 15721.6279  LR: 9.945344042725302e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6200/6898] Elapsed 86m 24s (remain 9m 42s) Loss: 0.0017(0.0029) Grad Norm: 197467.7812  LR: 9.94450144768652e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6300/6898] Elapsed 87m 49s (remain 8m 19s) Loss: 0.0000(0.0029) Grad Norm: 6008.7729  LR: 9.943652443609143e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6400/6898] Elapsed 89m 13s (remain 6m 55s) Loss: 0.0132(0.0029) Grad Norm: 475428.6875  LR: 9.942797031593645e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6500/6898] Elapsed 90m 37s (remain 5m 32s) Loss: 0.0118(0.0029) Grad Norm: 319917.9062  LR: 9.941935212748808e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6600/6898] Elapsed 92m 0s (remain 4m 8s) Loss: 0.0019(0.0029) Grad Norm: 93269.1484  LR: 9.941066988191714e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6700/6898] Elapsed 93m 20s (remain 2m 44s) Loss: 0.0014(0.0029) Grad Norm: 82498.7266  LR: 9.940192359047756e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6800/6898] Elapsed 94m 40s (remain 1m 21s) Loss: 0.0020(0.0029) Grad Norm: 256638.4844  LR: 9.93931132645062e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][6897/6898] Elapsed 96m 0s (remain 0m 0s) Loss: 0.0023(0.0029) Grad Norm: 70734.7109  LR: 9.938450607732207e-06\n",
      "Epoch 2 completed. Average loss: 0.0029\n",
      "Starting evaluation\n",
      "Starting validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1725] Elapsed 0m 0s (remain 13m 4s) Loss: 0.0008(0.0008) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [100/1725] Elapsed 0m 7s (remain 1m 53s) Loss: 0.0001(0.0028) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [200/1725] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0050(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [300/1725] Elapsed 0m 20s (remain 1m 35s) Loss: 0.0015(0.0031) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [400/1725] Elapsed 0m 26s (remain 1m 28s) Loss: -0.0012(0.0031) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [500/1725] Elapsed 0m 33s (remain 1m 21s) Loss: 0.0097(0.0029) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [600/1725] Elapsed 0m 40s (remain 1m 14s) Loss: 0.0084(0.0029) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [700/1725] Elapsed 0m 46s (remain 1m 8s) Loss: 0.0049(0.0030) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [800/1725] Elapsed 0m 53s (remain 1m 1s) Loss: 0.0068(0.0034) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [900/1725] Elapsed 1m 0s (remain 0m 54s) Loss: 0.0078(0.0035) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1000/1725] Elapsed 1m 6s (remain 0m 48s) Loss: -0.0004(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1100/1725] Elapsed 1m 13s (remain 0m 41s) Loss: 0.0003(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1200/1725] Elapsed 1m 19s (remain 0m 34s) Loss: 0.0019(0.0039) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1300/1725] Elapsed 1m 26s (remain 0m 28s) Loss: -0.0002(0.0039) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1400/1725] Elapsed 1m 33s (remain 0m 21s) Loss: 0.0064(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1500/1725] Elapsed 1m 39s (remain 0m 14s) Loss: 0.0022(0.0038) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1600/1725] Elapsed 1m 46s (remain 0m 8s) Loss: 0.0039(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1700/1725] Elapsed 1m 53s (remain 0m 1s) Loss: -0.0007(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1724/1725] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0042(0.0036) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.0029  avg_val_loss: 0.0036  time: 5887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Score: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Save Best Score: 0.9786 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "\n",
      "Starting training epoch 3 for fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/6898] Elapsed 0m 1s (remain 155m 49s) Loss: 0.0001(0.0001) Grad Norm: 971.6568  LR: 9.938441702975689e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][100/6898] Elapsed 1m 25s (remain 95m 58s) Loss: 0.0320(0.0025) Grad Norm: 58579.8867  LR: 9.937547994918364e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][200/6898] Elapsed 2m 46s (remain 92m 21s) Loss: 0.0030(0.0024) Grad Norm: 16482.6855  LR: 9.936647886835472e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][300/6898] Elapsed 4m 7s (remain 90m 18s) Loss: 0.0011(0.0023) Grad Norm: 2904.0078  LR: 9.935741379893732e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][400/6898] Elapsed 5m 27s (remain 88m 33s) Loss: 0.0000(0.0022) Grad Norm: 290.6802  LR: 9.934828475268154e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][500/6898] Elapsed 6m 50s (remain 87m 21s) Loss: 0.0000(0.0023) Grad Norm: 220.7211  LR: 9.933909174142042e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][600/6898] Elapsed 8m 10s (remain 85m 42s) Loss: 0.0050(0.0023) Grad Norm: 19468.2969  LR: 9.932983477706985e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][700/6898] Elapsed 9m 34s (remain 84m 38s) Loss: 0.0001(0.0022) Grad Norm: 737.6957  LR: 9.932051387162868e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][800/6898] Elapsed 10m 55s (remain 83m 13s) Loss: 0.0001(0.0023) Grad Norm: 1141.0597  LR: 9.931112903717864e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][900/6898] Elapsed 12m 18s (remain 81m 55s) Loss: 0.0000(0.0023) Grad Norm: 253.9905  LR: 9.93016802858843e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1000/6898] Elapsed 13m 39s (remain 80m 29s) Loss: 0.0003(0.0024) Grad Norm: 2651.0867  LR: 9.929216762999307e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1100/6898] Elapsed 15m 0s (remain 79m 2s) Loss: 0.0045(0.0024) Grad Norm: 16299.2500  LR: 9.928259108183523e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1200/6898] Elapsed 16m 24s (remain 77m 51s) Loss: 0.0017(0.0024) Grad Norm: 9947.3887  LR: 9.927295065382384e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1300/6898] Elapsed 17m 49s (remain 76m 41s) Loss: 0.0013(0.0025) Grad Norm: 5560.3589  LR: 9.926324635845478e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1400/6898] Elapsed 19m 13s (remain 75m 25s) Loss: 0.0001(0.0024) Grad Norm: 2337.9861  LR: 9.925347820830669e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1500/6898] Elapsed 20m 35s (remain 74m 3s) Loss: 0.0004(0.0025) Grad Norm: 13033.9131  LR: 9.924364621604103e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1600/6898] Elapsed 21m 57s (remain 72m 39s) Loss: 0.0012(0.0024) Grad Norm: 10811.7354  LR: 9.923375039440197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1700/6898] Elapsed 23m 22s (remain 71m 25s) Loss: 0.0000(0.0025) Grad Norm: 344.9766  LR: 9.922379075621642e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1800/6898] Elapsed 24m 44s (remain 70m 0s) Loss: 0.0019(0.0024) Grad Norm: 37766.0234  LR: 9.921376731439403e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][1900/6898] Elapsed 26m 5s (remain 68m 35s) Loss: 0.0002(0.0024) Grad Norm: 5273.7104  LR: 9.920368008192711e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2000/6898] Elapsed 27m 31s (remain 67m 21s) Loss: 0.0000(0.0025) Grad Norm: 308.2515  LR: 9.91935290718907e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2100/6898] Elapsed 28m 55s (remain 66m 2s) Loss: 0.0055(0.0024) Grad Norm: 35583.0508  LR: 9.918331429744247e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2200/6898] Elapsed 30m 20s (remain 64m 44s) Loss: 0.0002(0.0024) Grad Norm: 5920.8042  LR: 9.91730357718228e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2300/6898] Elapsed 31m 44s (remain 63m 24s) Loss: 0.0000(0.0025) Grad Norm: 61.2994  LR: 9.916269350835464e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2400/6898] Elapsed 33m 7s (remain 62m 2s) Loss: 0.0000(0.0025) Grad Norm: 53.8366  LR: 9.915228752044356e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2500/6898] Elapsed 34m 30s (remain 60m 40s) Loss: 0.0000(0.0024) Grad Norm: 45.5815  LR: 9.91418178215778e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2600/6898] Elapsed 35m 54s (remain 59m 18s) Loss: 0.0002(0.0024) Grad Norm: 5654.9902  LR: 9.913128442532809e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2700/6898] Elapsed 37m 15s (remain 57m 53s) Loss: 0.0002(0.0025) Grad Norm: 8241.7949  LR: 9.912068734534778e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2800/6898] Elapsed 38m 35s (remain 56m 26s) Loss: 0.0000(0.0024) Grad Norm: 130.7130  LR: 9.911002659537276e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][2900/6898] Elapsed 39m 57s (remain 55m 3s) Loss: 0.0017(0.0024) Grad Norm: 20098.3164  LR: 9.909930218922143e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3000/6898] Elapsed 41m 20s (remain 53m 41s) Loss: 0.0026(0.0024) Grad Norm: 41065.4844  LR: 9.908851414079471e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3100/6898] Elapsed 42m 43s (remain 52m 18s) Loss: 0.0025(0.0024) Grad Norm: 19602.5898  LR: 9.907766246407606e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3200/6898] Elapsed 44m 3s (remain 50m 53s) Loss: 0.0010(0.0024) Grad Norm: 14581.2744  LR: 9.906674717313131e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3300/6898] Elapsed 45m 23s (remain 49m 27s) Loss: 0.0000(0.0024) Grad Norm: 231.3525  LR: 9.905576828210884e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3400/6898] Elapsed 46m 43s (remain 48m 2s) Loss: 0.0003(0.0024) Grad Norm: 6948.9604  LR: 9.90447258052394e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3500/6898] Elapsed 48m 4s (remain 46m 38s) Loss: 0.0008(0.0024) Grad Norm: 23638.4727  LR: 9.903361975683626e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3600/6898] Elapsed 49m 24s (remain 45m 14s) Loss: 0.0083(0.0024) Grad Norm: 144409.2188  LR: 9.902245015129497e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3700/6898] Elapsed 50m 46s (remain 43m 51s) Loss: 0.0032(0.0024) Grad Norm: 23613.8945  LR: 9.901121700309353e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3800/6898] Elapsed 52m 6s (remain 42m 27s) Loss: 0.0064(0.0024) Grad Norm: 53046.6953  LR: 9.89999203267923e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][3900/6898] Elapsed 53m 27s (remain 41m 3s) Loss: 0.0000(0.0024) Grad Norm: 985.7111  LR: 9.898856013703398e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4000/6898] Elapsed 54m 47s (remain 39m 40s) Loss: 0.0000(0.0024) Grad Norm: 671.4966  LR: 9.897713644854359e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4100/6898] Elapsed 56m 9s (remain 38m 18s) Loss: 0.0011(0.0024) Grad Norm: 59631.6367  LR: 9.896564927612844e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4200/6898] Elapsed 57m 30s (remain 36m 55s) Loss: 0.0035(0.0024) Grad Norm: 66948.7109  LR: 9.895409863467817e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4300/6898] Elapsed 58m 51s (remain 35m 32s) Loss: 0.0076(0.0024) Grad Norm: 65566.1328  LR: 9.894248453916466e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4400/6898] Elapsed 60m 15s (remain 34m 11s) Loss: 0.0001(0.0024) Grad Norm: 2990.0598  LR: 9.893080700464203e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4500/6898] Elapsed 61m 38s (remain 32m 49s) Loss: 0.0006(0.0024) Grad Norm: 26430.2188  LR: 9.891906604624666e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4600/6898] Elapsed 63m 3s (remain 31m 28s) Loss: 0.0000(0.0024) Grad Norm: 1308.5687  LR: 9.890726167919712e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4700/6898] Elapsed 64m 27s (remain 30m 7s) Loss: 0.0015(0.0024) Grad Norm: 49054.6680  LR: 9.889539391879418e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4800/6898] Elapsed 65m 48s (remain 28m 44s) Loss: 0.0000(0.0024) Grad Norm: 1195.1071  LR: 9.888346278042074e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][4900/6898] Elapsed 67m 10s (remain 27m 22s) Loss: 0.0040(0.0024) Grad Norm: 136663.8906  LR: 9.887146827954192e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5000/6898] Elapsed 68m 35s (remain 26m 1s) Loss: 0.0000(0.0024) Grad Norm: 1203.9294  LR: 9.885941043170491e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5100/6898] Elapsed 69m 58s (remain 24m 39s) Loss: 0.0017(0.0024) Grad Norm: 160404.0625  LR: 9.884728925253906e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5200/6898] Elapsed 71m 21s (remain 23m 16s) Loss: 0.0000(0.0024) Grad Norm: 349.1620  LR: 9.883510475775576e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5300/6898] Elapsed 72m 42s (remain 21m 54s) Loss: 0.0000(0.0024) Grad Norm: 1027.7078  LR: 9.882285696314846e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5400/6898] Elapsed 74m 7s (remain 20m 32s) Loss: 0.0000(0.0024) Grad Norm: 224.1151  LR: 9.881054588459278e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5500/6898] Elapsed 75m 27s (remain 19m 9s) Loss: 0.0008(0.0024) Grad Norm: 41018.6680  LR: 9.87981715380462e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5600/6898] Elapsed 76m 47s (remain 17m 46s) Loss: 0.0001(0.0024) Grad Norm: 19576.3555  LR: 9.878573393954834e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5700/6898] Elapsed 78m 7s (remain 16m 24s) Loss: 0.0151(0.0024) Grad Norm: 111830.9844  LR: 9.87732331052207e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5800/6898] Elapsed 79m 31s (remain 15m 2s) Loss: 0.0001(0.0024) Grad Norm: 9332.6289  LR: 9.876066905126687e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5900/6898] Elapsed 80m 55s (remain 13m 40s) Loss: 0.0001(0.0024) Grad Norm: 12887.6445  LR: 9.874804179397224e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6000/6898] Elapsed 82m 16s (remain 12m 17s) Loss: 0.0007(0.0024) Grad Norm: 72563.9297  LR: 9.873535134970426e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6100/6898] Elapsed 83m 40s (remain 10m 55s) Loss: 0.0019(0.0024) Grad Norm: 53148.8242  LR: 9.872259773491219e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6200/6898] Elapsed 85m 5s (remain 9m 33s) Loss: 0.0007(0.0024) Grad Norm: 103980.8125  LR: 9.870978096612721e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6300/6898] Elapsed 86m 30s (remain 8m 11s) Loss: 0.0005(0.0024) Grad Norm: 91814.1406  LR: 9.869690105996235e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6400/6898] Elapsed 87m 53s (remain 6m 49s) Loss: 0.0001(0.0024) Grad Norm: 8484.7217  LR: 9.86839580331125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6500/6898] Elapsed 89m 16s (remain 5m 27s) Loss: 0.0114(0.0024) Grad Norm: 366892.0938  LR: 9.867095190235432e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6600/6898] Elapsed 90m 38s (remain 4m 4s) Loss: 0.0130(0.0024) Grad Norm: 606723.3750  LR: 9.86578826845463e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6700/6898] Elapsed 91m 59s (remain 2m 42s) Loss: 0.0027(0.0024) Grad Norm: 115773.4844  LR: 9.864475039662874e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6800/6898] Elapsed 93m 19s (remain 1m 19s) Loss: 0.0000(0.0024) Grad Norm: 1387.1295  LR: 9.863155505562356e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][6897/6898] Elapsed 94m 37s (remain 0m 0s) Loss: 0.0014(0.0024) Grad Norm: 166705.5312  LR: 9.86186953469538e-06\n",
      "Epoch 3 completed. Average loss: 0.0024\n",
      "Starting evaluation\n",
      "Starting validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1725] Elapsed 0m 0s (remain 12m 15s) Loss: -0.0005(-0.0005) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [100/1725] Elapsed 0m 7s (remain 1m 53s) Loss: 0.0023(0.0032) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [200/1725] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0069(0.0044) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [300/1725] Elapsed 0m 20s (remain 1m 35s) Loss: 0.0007(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [400/1725] Elapsed 0m 26s (remain 1m 28s) Loss: -0.0002(0.0035) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [500/1725] Elapsed 0m 33s (remain 1m 21s) Loss: 0.0070(0.0033) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [600/1725] Elapsed 0m 40s (remain 1m 15s) Loss: 0.0074(0.0033) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [700/1725] Elapsed 0m 46s (remain 1m 8s) Loss: 0.0078(0.0033) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [800/1725] Elapsed 0m 53s (remain 1m 1s) Loss: 0.0098(0.0039) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [900/1725] Elapsed 1m 0s (remain 0m 54s) Loss: 0.0099(0.0041) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1000/1725] Elapsed 1m 6s (remain 0m 48s) Loss: -0.0004(0.0044) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1100/1725] Elapsed 1m 13s (remain 0m 41s) Loss: 0.0056(0.0045) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1200/1725] Elapsed 1m 19s (remain 0m 34s) Loss: 0.0051(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1300/1725] Elapsed 1m 26s (remain 0m 28s) Loss: 0.0015(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1400/1725] Elapsed 1m 33s (remain 0m 21s) Loss: 0.0093(0.0046) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1500/1725] Elapsed 1m 39s (remain 0m 14s) Loss: 0.0031(0.0045) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1600/1725] Elapsed 1m 46s (remain 0m 8s) Loss: 0.0052(0.0044) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1700/1725] Elapsed 1m 53s (remain 0m 1s) Loss: -0.0013(0.0042) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1724/1725] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0026(0.0042) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.0024  avg_val_loss: 0.0042  time: 5804s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Score: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Save Best Score: 0.9789 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "\n",
      "Starting training epoch 4 for fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/6898] Elapsed 0m 1s (remain 147m 20s) Loss: 0.0000(0.0000) Grad Norm: 9.9372  LR: 9.861856246381599e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][100/6898] Elapsed 1m 21s (remain 91m 34s) Loss: 0.0033(0.0021) Grad Norm: 8058.5752  LR: 9.860524232823562e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][200/6898] Elapsed 2m 42s (remain 90m 16s) Loss: 0.0052(0.0023) Grad Norm: 14763.0752  LR: 9.859185919077785e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][300/6898] Elapsed 4m 3s (remain 89m 5s) Loss: 0.0000(0.0022) Grad Norm: 53.9231  LR: 9.857841306878984e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][400/6898] Elapsed 5m 23s (remain 87m 22s) Loss: 0.0087(0.0022) Grad Norm: 50875.2344  LR: 9.856490397970038e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][500/6898] Elapsed 6m 44s (remain 85m 59s) Loss: 0.0013(0.0021) Grad Norm: 5480.8369  LR: 9.85513319410199e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][600/6898] Elapsed 8m 4s (remain 84m 32s) Loss: 0.0028(0.0021) Grad Norm: 24851.9707  LR: 9.853769697034036e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][700/6898] Elapsed 9m 25s (remain 83m 14s) Loss: 0.0020(0.0021) Grad Norm: 9998.7109  LR: 9.852399908533541e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][800/6898] Elapsed 10m 49s (remain 82m 20s) Loss: 0.0001(0.0022) Grad Norm: 1955.9009  LR: 9.851023830376014e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][900/6898] Elapsed 12m 9s (remain 80m 53s) Loss: 0.0000(0.0022) Grad Norm: 123.9668  LR: 9.84964146434512e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1000/6898] Elapsed 13m 32s (remain 79m 44s) Loss: 0.0001(0.0022) Grad Norm: 2558.2861  LR: 9.848252812232679e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1100/6898] Elapsed 14m 55s (remain 78m 36s) Loss: 0.0000(0.0022) Grad Norm: 238.1465  LR: 9.846857875838652e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1200/6898] Elapsed 16m 20s (remain 77m 29s) Loss: 0.0002(0.0022) Grad Norm: 3478.5564  LR: 9.845456656971152e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1300/6898] Elapsed 17m 43s (remain 76m 16s) Loss: 0.0000(0.0021) Grad Norm: 199.0674  LR: 9.844049157446425e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1400/6898] Elapsed 19m 5s (remain 74m 54s) Loss: 0.0023(0.0021) Grad Norm: 26379.8027  LR: 9.842635379088873e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1500/6898] Elapsed 20m 29s (remain 73m 39s) Loss: 0.0001(0.0021) Grad Norm: 2559.6621  LR: 9.841215323731023e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1600/6898] Elapsed 21m 51s (remain 72m 19s) Loss: 0.0010(0.0020) Grad Norm: 10155.3184  LR: 9.839788993213548e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1700/6898] Elapsed 23m 15s (remain 71m 5s) Loss: 0.0002(0.0021) Grad Norm: 934.9715  LR: 9.838356389385249e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1800/6898] Elapsed 24m 40s (remain 69m 51s) Loss: 0.0018(0.0021) Grad Norm: 15437.2266  LR: 9.836917514103056e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][1900/6898] Elapsed 26m 4s (remain 68m 33s) Loss: 0.0094(0.0021) Grad Norm: 45673.3203  LR: 9.83547236923204e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2000/6898] Elapsed 27m 29s (remain 67m 17s) Loss: 0.0045(0.0021) Grad Norm: 23991.4062  LR: 9.834020956645386e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2100/6898] Elapsed 28m 55s (remain 66m 1s) Loss: 0.0029(0.0021) Grad Norm: 103938.2578  LR: 9.832563278224407e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2200/6898] Elapsed 30m 19s (remain 64m 43s) Loss: 0.0022(0.0021) Grad Norm: 43361.9727  LR: 9.831099335858542e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2300/6898] Elapsed 31m 44s (remain 63m 24s) Loss: 0.0000(0.0020) Grad Norm: 127.2610  LR: 9.829629131445342e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2400/6898] Elapsed 33m 9s (remain 62m 5s) Loss: 0.0012(0.0020) Grad Norm: 29916.1387  LR: 9.828152666890482e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2500/6898] Elapsed 34m 35s (remain 60m 49s) Loss: 0.0019(0.0020) Grad Norm: 14016.8164  LR: 9.826669944107747e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2600/6898] Elapsed 36m 0s (remain 59m 29s) Loss: 0.0029(0.0021) Grad Norm: 71156.4609  LR: 9.825180965019035e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2700/6898] Elapsed 37m 24s (remain 58m 7s) Loss: 0.0015(0.0021) Grad Norm: 21004.0703  LR: 9.823685731554353e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2800/6898] Elapsed 38m 48s (remain 56m 45s) Loss: 0.0022(0.0021) Grad Norm: 22464.6973  LR: 9.822184245651817e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2900/6898] Elapsed 40m 11s (remain 55m 22s) Loss: 0.0032(0.0021) Grad Norm: 8307.8115  LR: 9.820676509257641e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3000/6898] Elapsed 41m 35s (remain 54m 1s) Loss: 0.0001(0.0021) Grad Norm: 6487.0615  LR: 9.81916252432615e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3100/6898] Elapsed 42m 59s (remain 52m 38s) Loss: 0.0008(0.0021) Grad Norm: 26762.3574  LR: 9.817642292819766e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3200/6898] Elapsed 44m 23s (remain 51m 15s) Loss: 0.0000(0.0021) Grad Norm: 239.4819  LR: 9.816115816709e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3300/6898] Elapsed 45m 43s (remain 49m 48s) Loss: 0.0020(0.0021) Grad Norm: 21894.1387  LR: 9.814583097972465e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3400/6898] Elapsed 47m 4s (remain 48m 23s) Loss: 0.0000(0.0021) Grad Norm: 805.0276  LR: 9.813044138596865e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3500/6898] Elapsed 48m 24s (remain 46m 58s) Loss: 0.0146(0.0021) Grad Norm: 154631.8906  LR: 9.81149894057699e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3600/6898] Elapsed 49m 44s (remain 45m 32s) Loss: 0.0016(0.0021) Grad Norm: 43181.9883  LR: 9.809947505915718e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3700/6898] Elapsed 51m 5s (remain 44m 8s) Loss: 0.0024(0.0021) Grad Norm: 17133.0371  LR: 9.808389836624013e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3800/6898] Elapsed 52m 26s (remain 42m 43s) Loss: 0.0000(0.0021) Grad Norm: 226.1469  LR: 9.806825934720916e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][3900/6898] Elapsed 53m 48s (remain 41m 20s) Loss: 0.0001(0.0021) Grad Norm: 1869.7736  LR: 9.80525580223355e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4000/6898] Elapsed 55m 8s (remain 39m 55s) Loss: 0.0075(0.0021) Grad Norm: 228850.7344  LR: 9.803679441197112e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4100/6898] Elapsed 56m 27s (remain 38m 30s) Loss: 0.0001(0.0021) Grad Norm: 4077.8914  LR: 9.802096853654876e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4200/6898] Elapsed 57m 46s (remain 37m 5s) Loss: 0.0013(0.0021) Grad Norm: 58771.7773  LR: 9.800508041658182e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4300/6898] Elapsed 59m 6s (remain 35m 41s) Loss: 0.0055(0.0021) Grad Norm: 113884.1484  LR: 9.79891300726644e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4400/6898] Elapsed 60m 30s (remain 34m 19s) Loss: 0.0001(0.0021) Grad Norm: 11356.9111  LR: 9.797311752547129e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4500/6898] Elapsed 61m 52s (remain 32m 56s) Loss: 0.0000(0.0021) Grad Norm: 96.8502  LR: 9.795704279575783e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4600/6898] Elapsed 63m 13s (remain 31m 33s) Loss: 0.0054(0.0021) Grad Norm: 394354.5625  LR: 9.794090590436006e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4700/6898] Elapsed 64m 35s (remain 30m 11s) Loss: 0.0000(0.0021) Grad Norm: 40.0782  LR: 9.792470687219448e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4800/6898] Elapsed 66m 1s (remain 28m 50s) Loss: 0.0181(0.0021) Grad Norm: 120726.6406  LR: 9.790844572025823e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][4900/6898] Elapsed 67m 24s (remain 27m 28s) Loss: 0.0019(0.0021) Grad Norm: 66487.7500  LR: 9.789212246962893e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5000/6898] Elapsed 68m 48s (remain 26m 6s) Loss: 0.0007(0.0021) Grad Norm: 75419.0078  LR: 9.787573714146472e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5100/6898] Elapsed 70m 12s (remain 24m 43s) Loss: 0.0000(0.0021) Grad Norm: 290.4821  LR: 9.785928975700414e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5200/6898] Elapsed 71m 36s (remain 23m 21s) Loss: 0.0001(0.0021) Grad Norm: 17887.9180  LR: 9.784278033756623e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5300/6898] Elapsed 73m 0s (remain 21m 59s) Loss: 0.0067(0.0021) Grad Norm: 273493.0938  LR: 9.78262089045504e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5400/6898] Elapsed 74m 22s (remain 20m 37s) Loss: 0.0000(0.0021) Grad Norm: 106.0208  LR: 9.780957547943653e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5500/6898] Elapsed 75m 46s (remain 19m 14s) Loss: 0.0000(0.0021) Grad Norm: 1328.1692  LR: 9.779288008378469e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5600/6898] Elapsed 77m 7s (remain 17m 51s) Loss: 0.0009(0.0021) Grad Norm: 121603.7500  LR: 9.777612273923544e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5700/6898] Elapsed 78m 30s (remain 16m 29s) Loss: 0.0000(0.0021) Grad Norm: 1623.0942  LR: 9.775930346750953e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5800/6898] Elapsed 79m 50s (remain 15m 5s) Loss: 0.0000(0.0021) Grad Norm: 14.7922  LR: 9.774242229040803e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5900/6898] Elapsed 81m 10s (remain 13m 42s) Loss: 0.0013(0.0021) Grad Norm: 53775.1562  LR: 9.772547922981223e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6000/6898] Elapsed 82m 34s (remain 12m 20s) Loss: 0.0019(0.0021) Grad Norm: 395896.4375  LR: 9.770847430768366e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6100/6898] Elapsed 83m 58s (remain 10m 58s) Loss: 0.0016(0.0021) Grad Norm: 218470.3906  LR: 9.769140754606401e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6200/6898] Elapsed 85m 21s (remain 9m 35s) Loss: 0.0000(0.0021) Grad Norm: 4561.6328  LR: 9.767427896707512e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6300/6898] Elapsed 86m 45s (remain 8m 13s) Loss: 0.0000(0.0021) Grad Norm: 3448.0276  LR: 9.7657088592919e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6400/6898] Elapsed 88m 11s (remain 6m 50s) Loss: 0.0020(0.0021) Grad Norm: 241821.4062  LR: 9.763983644587768e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6500/6898] Elapsed 89m 34s (remain 5m 28s) Loss: 0.0018(0.0021) Grad Norm: 167694.9062  LR: 9.762252254831338e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6600/6898] Elapsed 90m 55s (remain 4m 5s) Loss: 0.0053(0.0021) Grad Norm: 326622.4688  LR: 9.760514692266823e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6700/6898] Elapsed 92m 17s (remain 2m 42s) Loss: 0.0000(0.0020) Grad Norm: 245.5715  LR: 9.758770959146443e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6800/6898] Elapsed 93m 40s (remain 1m 20s) Loss: 0.0000(0.0020) Grad Norm: 1997.6903  LR: 9.75702105773042e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][6897/6898] Elapsed 95m 2s (remain 0m 0s) Loss: 0.0017(0.0021) Grad Norm: 218906.9844  LR: 9.755317762004239e-06\n",
      "Epoch 4 completed. Average loss: 0.0021\n",
      "Starting evaluation\n",
      "Starting validation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [0/1725] Elapsed 0m 0s (remain 11m 34s) Loss: -0.0009(-0.0009) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [100/1725] Elapsed 0m 7s (remain 1m 52s) Loss: 0.0055(0.0042) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [200/1725] Elapsed 0m 13s (remain 1m 43s) Loss: 0.0045(0.0049) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [300/1725] Elapsed 0m 20s (remain 1m 35s) Loss: 0.0017(0.0040) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [400/1725] Elapsed 0m 26s (remain 1m 28s) Loss: -0.0005(0.0040) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [500/1725] Elapsed 0m 33s (remain 1m 21s) Loss: 0.0011(0.0037) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [600/1725] Elapsed 0m 40s (remain 1m 14s) Loss: 0.0129(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [700/1725] Elapsed 0m 46s (remain 1m 8s) Loss: 0.0059(0.0036) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [800/1725] Elapsed 0m 53s (remain 1m 1s) Loss: 0.0091(0.0041) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [900/1725] Elapsed 0m 59s (remain 0m 54s) Loss: 0.0028(0.0043) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1000/1725] Elapsed 1m 6s (remain 0m 48s) Loss: 0.0020(0.0045) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1100/1725] Elapsed 1m 13s (remain 0m 41s) Loss: 0.0004(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1200/1725] Elapsed 1m 19s (remain 0m 34s) Loss: 0.0061(0.0048) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1300/1725] Elapsed 1m 26s (remain 0m 28s) Loss: 0.0003(0.0048) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1400/1725] Elapsed 1m 33s (remain 0m 21s) Loss: 0.0079(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1500/1725] Elapsed 1m 39s (remain 0m 14s) Loss: 0.0028(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1600/1725] Elapsed 1m 46s (remain 0m 8s) Loss: 0.0041(0.0047) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1700/1725] Elapsed 1m 53s (remain 0m 1s) Loss: 0.0029(0.0045) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [1724/1725] Elapsed 1m 54s (remain 0m 0s) Loss: 0.0029(0.0045) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.0021  avg_val_loss: 0.0045  time: 5828s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Score: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Save Best Score: 0.9790 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== CV ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [fold0] avg_train_loss â–ˆâ–„â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   [fold0] avg_val_loss â–â–â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          [fold0] epoch â–â–ƒâ–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          [fold0] score â–â–†â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: [fold0] avg_train_loss 0.00205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   [fold0] avg_val_loss 0.00446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          [fold0] epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          [fold0] score 0.97902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m/workspace/deberta-v3-large\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public/runs/kl09y3t4?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250211_210932-kl09y3t4/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    CFG.debug = True\n",
    "\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "\n",
    "        # Run training for a single fold in debug mode or multiple folds otherwise\n",
    "        if CFG.debug:\n",
    "            fold = 0  # In debug mode, we only use fold 0 along with 2-3 epochs \n",
    "            if fold in CFG.trn_fold:\n",
    "                oof_df = run_fold_training(oof_df, fold)\n",
    "        else:\n",
    "            for fold in range(CFG.n_fold):  # For all folds in non-debug mode\n",
    "                if fold in CFG.trn_fold:\n",
    "                    oof_df = run_fold_training(oof_df, fold)\n",
    "\n",
    "        # Final evaluation and saving results\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        evaluate_results(oof_df)  # Final evaluation of all results\n",
    "        oof_df.to_pickle(OUTPUT_DIR + 'oof_df.pkl')\n",
    "\n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3075283,
     "sourceId": 33607,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 49736,
     "modelInstanceId": 35444,
     "sourceId": 42188,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nbme_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23528.973067,
   "end_time": "2025-02-12T03:41:24.827279",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/ft-pl.ipynb",
   "output_path": "deberta-with-pseudo.ipynb",
   "parameters": {},
   "start_time": "2025-02-11T21:09:15.854212",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}