{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc14eb4",
   "metadata": {
    "papermill": {
     "duration": 0.014043,
     "end_time": "2025-02-11T18:30:39.180287",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.166244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training deberta-v3-large model to generate high quality pseudolabels\n",
    "\n",
    "Initially deberta-v3-large model raises OOM error. \n",
    "\n",
    "Optimized the training pipeline via Pytorch\n",
    "- Gradient accumulation\n",
    "- Gradient checkpoint\n",
    "- Using bfloat data types\n",
    "- Autocast\n",
    "\n",
    "1 fold (with 4-5 epochs) takes around ~5 hours, each epoch ~50 minutes. %87+ accuracy. (See notebook version 6)\n",
    "\n",
    "Another approach would be to use [huggingface accelerator](https://huggingface.co/docs/accelerate/en/index) as it automates this process without the need to customize manually as well as distribution of training while using multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af383fe",
   "metadata": {
    "papermill": {
     "duration": 0.009497,
     "end_time": "2025-02-11T18:30:39.200195",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.190698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Deberta-v3-large?\n",
    "![Comparison of BERT variants in 2025](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/modernbert/modernbert_pareto_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d41ae1",
   "metadata": {
    "papermill": {
     "duration": 0.009574,
     "end_time": "2025-02-11T18:30:39.221606",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.212032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c63e94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:39.245966Z",
     "iopub.status.busy": "2025-02-11T18:30:39.245741Z",
     "iopub.status.idle": "2025-02-11T18:30:39.255655Z",
     "shell.execute_reply": "2025-02-11T18:30:39.254692Z"
    },
    "papermill": {
     "duration": 0.024137,
     "end_time": "2025-02-11T18:30:39.257186",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.233049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os, shutil\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.path.dirname(os.getcwd()), 'deberta-v3-large-finetuned-with-pseudolabels/')\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "for item in os.listdir(OUTPUT_DIR):\n",
    "    item_path = os.path.join(OUTPUT_DIR, item)\n",
    "    if os.path.isfile(item_path):  # If it's a file, remove it\n",
    "        os.remove(item_path)\n",
    "        print(f\"Removed file: {item}\")\n",
    "    elif os.path.isdir(item_path):  # If it's a directory, remove it\n",
    "        shutil.rmtree(item_path)\n",
    "        print(f\"Removed folder: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c07df8",
   "metadata": {
    "papermill": {
     "duration": 0.011993,
     "end_time": "2025-02-11T18:30:39.282575",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.270582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d10142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:39.308122Z",
     "iopub.status.busy": "2025-02-11T18:30:39.307916Z",
     "iopub.status.idle": "2025-02-11T18:30:51.728318Z",
     "shell.execute_reply": "2025-02-11T18:30:51.727152Z"
    },
    "papermill": {
     "duration": 12.436826,
     "end_time": "2025-02-11T18:30:51.730143",
     "exception": false,
     "start_time": "2025-02-11T18:30:39.293317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.48.3\n",
      "Uninstalling transformers-4.48.3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully uninstalled transformers-4.48.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tokenizer as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from tokenizers) (0.28.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/nbme_train/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.21.0\n",
      "transformers.__version__: 4.48.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('python -m pip install transformers>=4.48.0')\n",
    "os.system('pip uninstall -y tokenizer')\n",
    "os.system('python -m pip install tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca0954c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:51.755480Z",
     "iopub.status.busy": "2025-02-11T18:30:51.755077Z",
     "iopub.status.idle": "2025-02-11T18:30:52.587994Z",
     "shell.execute_reply": "2025-02-11T18:30:52.587171Z"
    },
    "papermill": {
     "duration": 0.846015,
     "end_time": "2025-02-11T18:30:52.590041",
     "exception": false,
     "start_time": "2025-02-11T18:30:51.744026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=True\n",
    "    competition='NBME'\n",
    "    _wandb_kernel='zehra'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    # model=\"/kaggle/input/deberta-v3-large/pytorch/0501/1\" # if running on Kaggle, use this path \n",
    "    model = \"/workspace/deberta-v3-large\" # if running on local machine, use this path  \n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=1 #0.05\n",
    "    num_warmup_steps=0\n",
    "    epochs=5\n",
    "    encoder_lr = 1e-5 #encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size = 12 #batch_size=16\n",
    "    fc_dropout=0.2\n",
    "    max_len=512\n",
    "    weight_decay=0.1 #0.01\n",
    "    gradient_accumulation_steps=2 #1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    CFG.trn_fold = [0]\n",
    "\n",
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ad4b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:52.625399Z",
     "iopub.status.busy": "2025-02-11T18:30:52.624833Z",
     "iopub.status.idle": "2025-02-11T18:30:54.368058Z",
     "shell.execute_reply": "2025-02-11T18:30:54.367447Z"
    },
    "papermill": {
     "duration": 1.761584,
     "end_time": "2025-02-11T18:30:54.369640",
     "exception": false,
     "start_time": "2025-02-11T18:30:52.608056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to use your W&B account, create a .env file in the parent folder and provide your W&B access token as WANDB_API_KEY. \n",
      "Get your W&B access token from here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-moose-628529071760834444\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20250211_183053-v5xaqz69\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/workspace/deberta-v3-large\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/anony-moose-628529071760834444/NBME-Public/runs/v5xaqz69?apiKey=e17c3e277c305c3106a5fedd7c64321c1329fc02\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Do NOT share these links with anyone. They can be used to claim your runs.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb: local notebook login\n",
    "# ====================================================\n",
    "if CFG.wandb:\n",
    "    \n",
    "    import wandb\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    # Load environment variables from .env file in the parent folder\n",
    "    load_dotenv(os.path.join(os.path.dirname(os.getcwd()), '.env'))\n",
    "\n",
    "    secret_value_0 = os.getenv(\"WANDB_API_KEY\")\n",
    "    if secret_value_0:\n",
    "        wandb.login(key=secret_value_0)\n",
    "        anony = None\n",
    "    else:\n",
    "        anony = \"must\"\n",
    "        print('If you want to use your W&B account, create a .env file in the parent folder and provide your W&B access token as WANDB_API_KEY. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n",
    "\n",
    "    def class2dict(f):\n",
    "        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "    run = wandb.init(project='NBME-Public', \n",
    "                     name=CFG.model,\n",
    "                     config=class2dict(CFG),\n",
    "                     group=CFG.model,\n",
    "                     job_type=\"train\",\n",
    "                     anonymous=anony)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9a7ed",
   "metadata": {
    "papermill": {
     "duration": 0.009901,
     "end_time": "2025-02-11T18:30:54.391702",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.381801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98fbf50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:54.417562Z",
     "iopub.status.busy": "2025-02-11T18:30:54.417194Z",
     "iopub.status.idle": "2025-02-11T18:30:54.426496Z",
     "shell.execute_reply": "2025-02-11T18:30:54.425840Z"
    },
    "papermill": {
     "duration": 0.022562,
     "end_time": "2025-02-11T18:30:54.427566",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.405004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300d65ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:54.448975Z",
     "iopub.status.busy": "2025-02-11T18:30:54.448749Z",
     "iopub.status.idle": "2025-02-11T18:30:54.458947Z",
     "shell.execute_reply": "2025-02-11T18:30:54.458443Z"
    },
    "papermill": {
     "duration": 0.020821,
     "end_time": "2025-02-11T18:30:54.459854",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.439033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## UPDATED FOR HANDLING NONEs in THE PSEUDOLABELS / only including confident inferences\n",
    "import ast\n",
    "\n",
    "# Update the create_labels_for_scoring function\n",
    "def create_labels_for_scoring(df):\n",
    "    # Initialize the 'location_for_create_labels' column with empty lists\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst and lst != '':  # Check if lst is not None or empty\n",
    "            # Ensure lst is a list of strings\n",
    "            if isinstance(lst, str):\n",
    "                lst = [lst]\n",
    "            elif isinstance(lst, list):\n",
    "                lst = [str(item) for item in lst]\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "\n",
    "    # Create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    \n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbb68f",
   "metadata": {
    "papermill": {
     "duration": 0.009138,
     "end_time": "2025-02-11T18:30:54.479684",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.470546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1113bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:54.499387Z",
     "iopub.status.busy": "2025-02-11T18:30:54.499180Z",
     "iopub.status.idle": "2025-02-11T18:30:54.506282Z",
     "shell.execute_reply": "2025-02-11T18:30:54.505793Z"
    },
    "papermill": {
     "duration": 0.017621,
     "end_time": "2025-02-11T18:30:54.507231",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.489610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412dea5",
   "metadata": {
    "papermill": {
     "duration": 0.010239,
     "end_time": "2025-02-11T18:30:54.528221",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.517982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625d5342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:54.548649Z",
     "iopub.status.busy": "2025-02-11T18:30:54.548382Z",
     "iopub.status.idle": "2025-02-11T18:30:55.063463Z",
     "shell.execute_reply": "2025-02-11T18:30:55.062752Z"
    },
    "papermill": {
     "duration": 0.526813,
     "end_time": "2025-02-11T18:30:55.064571",
     "exception": false,
     "start_time": "2025-02-11T18:30:54.537758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (14300, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (143, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_notes.shape: (42146, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('/workspace/data/train.csv')\n",
    "train['annotation'] = train['annotation'].apply(ast.literal_eval)\n",
    "train['location'] = train['location'].apply(ast.literal_eval)\n",
    "features = pd.read_csv('/workspace/data/features.csv')\n",
    "def preprocess_features(features):\n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "features = preprocess_features(features)\n",
    "patient_notes = pd.read_csv('/workspace/data/patient_notes.csv')\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ec0d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.087252Z",
     "iopub.status.busy": "2025-02-11T18:30:55.087026Z",
     "iopub.status.idle": "2025-02-11T18:30:55.103446Z",
     "shell.execute_reply": "2025-02-11T18:30:55.102834Z"
    },
    "papermill": {
     "duration": 0.028391,
     "end_time": "2025-02-11T18:30:55.104417",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.076026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>95333_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>912</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>95333_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>913</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>95333_914</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>914</td>\n",
       "      <td>[photobia]</td>\n",
       "      <td>[274 282]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>95333_915</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>915</td>\n",
       "      <td>[no sick contacts]</td>\n",
       "      <td>[421 437]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>95333_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>916</td>\n",
       "      <td>[Subjective fever]</td>\n",
       "      <td>[314 330]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  case_num  pn_num  feature_num                              annotation          location  annotation_length\n",
       "0      00016_000         0      16            0          [dad with recent heart attcak]         [696 724]                  1\n",
       "1      00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                  1\n",
       "2      00016_002         0      16            2                        [chest pressure]         [203 217]                  1\n",
       "3      00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                  2\n",
       "4      00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                  1\n",
       "...          ...       ...     ...          ...                                     ...               ...                ...\n",
       "14295  95333_912         9   95333          912                                      []                []                  0\n",
       "14296  95333_913         9   95333          913                                      []                []                  0\n",
       "14297  95333_914         9   95333          914                              [photobia]         [274 282]                  1\n",
       "14298  95333_915         9   95333          915                      [no sick contacts]         [421 437]                  1\n",
       "14299  95333_916         9   95333          916                      [Subjective fever]         [314 330]                  1\n",
       "\n",
       "[14300 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['annotation_length'] = train['annotation'].apply(len) # refers to number of annotation\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20aae67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.129174Z",
     "iopub.status.busy": "2025-02-11T18:30:55.128834Z",
     "iopub.status.idle": "2025-02-11T18:30:55.627765Z",
     "shell.execute_reply": "2025-02-11T18:30:55.626796Z"
    },
    "papermill": {
     "duration": 0.512518,
     "end_time": "2025-02-11T18:30:55.629079",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.116561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>fold</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000_006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[521 526]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001_004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[179 195]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001_006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[347 353]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001_007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[220 235]</td>\n",
       "      <td>Shortness-of-breath</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001_011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[1 5]</td>\n",
       "      <td>17-year</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122512</th>\n",
       "      <td>95331_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>[283 302, 401 421]</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122513</th>\n",
       "      <td>95331_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "      <td>[8 9]</td>\n",
       "      <td>Female</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122516</th>\n",
       "      <td>95332_906</td>\n",
       "      <td>9</td>\n",
       "      <td>95332</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>[319 327]</td>\n",
       "      <td>Vomiting</td>\n",
       "      <td>Ms. Madden is a 20yo female who presents with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122518</th>\n",
       "      <td>95334_901</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>[13 18]</td>\n",
       "      <td>20-year</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122519</th>\n",
       "      <td>95334_904</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>[41 49, 136 143]</td>\n",
       "      <td>Global-headache-OR-diffuse-headache</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86232 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  case_num  pn_num  feature_num  fold            location                         feature_text                                         pn_history\n",
       "0       00000_006         0       0            6     1           [521 526]                         Adderall-use  17-year-old male, has come to the student heal...\n",
       "1       00001_004         0       1            4     1           [179 195]                          Lightheaded  17 yo male with recurrent palpitations for the...\n",
       "2       00001_006         0       1            6     1           [347 353]                         Adderall-use  17 yo male with recurrent palpitations for the...\n",
       "3       00001_007         0       1            7     1           [220 235]                  Shortness-of-breath  17 yo male with recurrent palpitations for the...\n",
       "4       00001_011         0       1           11     1               [1 5]                              17-year  17 yo male with recurrent palpitations for the...\n",
       "...           ...       ...     ...          ...   ...                 ...                                  ...                                                ...\n",
       "122512  95331_912         9   95331          912     1  [283 302, 401 421]          Family-history-of-migraines  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "122513  95331_913         9   95331          913     1               [8 9]                               Female  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...\n",
       "122516  95332_906         9   95332          906     1           [319 327]                             Vomiting  Ms. Madden is a 20yo female who presents with ...\n",
       "122518  95334_901         9   95334          901     1             [13 18]                              20-year  patient is a 20 yo F who presents with a heada...\n",
       "122519  95334_904         9   95334          904     1    [41 49, 136 143]  Global-headache-OR-diffuse-headache  patient is a 20 yo F who presents with a heada...\n",
       "\n",
       "[86232 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels = pd.read_csv('/workspace/data/pseudolabels.csv')\n",
    "pseudolabels =  pseudolabels.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "pseudolabels = pseudolabels.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "\n",
    "pseudolabels = pseudolabels.dropna(subset=['location'])\n",
    "pseudolabels = pseudolabels[pseudolabels['location'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "def convert_location_format(location):\n",
    "    if pd.isna(location) or not location:\n",
    "        return []\n",
    "    if isinstance(location, str):\n",
    "        return [loc.strip() for loc in location.split(';')]\n",
    "    return location\n",
    "\n",
    "pseudolabels['location'] = pseudolabels['location'].apply(convert_location_format)\n",
    "\n",
    "pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d7e01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.657749Z",
     "iopub.status.busy": "2025-02-11T18:30:55.657266Z",
     "iopub.status.idle": "2025-02-11T18:30:55.683012Z",
     "shell.execute_reply": "2025-02-11T18:30:55.682118Z"
    },
    "papermill": {
     "duration": 0.039983,
     "end_time": "2025-02-11T18:30:55.684560",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.644577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pseudolabels['annotation_length'] = pseudolabels['location'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d6094e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.715215Z",
     "iopub.status.busy": "2025-02-11T18:30:55.714856Z",
     "iopub.status.idle": "2025-02-11T18:30:55.729222Z",
     "shell.execute_reply": "2025-02-11T18:30:55.728542Z"
    },
    "papermill": {
     "duration": 0.030365,
     "end_time": "2025-02-11T18:30:55.730499",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.700134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>fold</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000_006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[521 526]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001_004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[179 195]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001_006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[347 353]</td>\n",
       "      <td>Adderall-use</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001_007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[220 235]</td>\n",
       "      <td>Shortness-of-breath</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001_011</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[1 5]</td>\n",
       "      <td>17-year</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122512</th>\n",
       "      <td>95331_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>912</td>\n",
       "      <td>1</td>\n",
       "      <td>[283 302, 401 421]</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122513</th>\n",
       "      <td>95331_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95331</td>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "      <td>[8 9]</td>\n",
       "      <td>Female</td>\n",
       "      <td>A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122516</th>\n",
       "      <td>95332_906</td>\n",
       "      <td>9</td>\n",
       "      <td>95332</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "      <td>[319 327]</td>\n",
       "      <td>Vomiting</td>\n",
       "      <td>Ms. Madden is a 20yo female who presents with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122518</th>\n",
       "      <td>95334_901</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>[13 18]</td>\n",
       "      <td>20-year</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122519</th>\n",
       "      <td>95334_904</td>\n",
       "      <td>9</td>\n",
       "      <td>95334</td>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "      <td>[41 49, 136 143]</td>\n",
       "      <td>Global-headache-OR-diffuse-headache</td>\n",
       "      <td>patient is a 20 yo F who presents with a heada...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86232 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  case_num  pn_num  feature_num  fold            location                         feature_text                                         pn_history  annotation_length\n",
       "0       00000_006         0       0            6     1           [521 526]                         Adderall-use  17-year-old male, has come to the student heal...                  1\n",
       "1       00001_004         0       1            4     1           [179 195]                          Lightheaded  17 yo male with recurrent palpitations for the...                  1\n",
       "2       00001_006         0       1            6     1           [347 353]                         Adderall-use  17 yo male with recurrent palpitations for the...                  1\n",
       "3       00001_007         0       1            7     1           [220 235]                  Shortness-of-breath  17 yo male with recurrent palpitations for the...                  1\n",
       "4       00001_011         0       1           11     1               [1 5]                              17-year  17 yo male with recurrent palpitations for the...                  1\n",
       "...           ...       ...     ...          ...   ...                 ...                                  ...                                                ...                ...\n",
       "122512  95331_912         9   95331          912     1  [283 302, 401 421]          Family-history-of-migraines  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...                  2\n",
       "122513  95331_913         9   95331          913     1               [8 9]                               Female  A 20 YO F CAME COMPLAIN A DULL 8/10 HEADACHE T...                  1\n",
       "122516  95332_906         9   95332          906     1           [319 327]                             Vomiting  Ms. Madden is a 20yo female who presents with ...                  1\n",
       "122518  95334_901         9   95334          901     1             [13 18]                              20-year  patient is a 20 yo F who presents with a heada...                  1\n",
       "122519  95334_904         9   95334          904     1    [41 49, 136 143]  Global-headache-OR-diffuse-headache  patient is a 20 yo F who presents with a heada...                  2\n",
       "\n",
       "[86232 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudolabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a621400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.760393Z",
     "iopub.status.busy": "2025-02-11T18:30:55.760051Z",
     "iopub.status.idle": "2025-02-11T18:30:55.771432Z",
     "shell.execute_reply": "2025-02-11T18:30:55.770533Z"
    },
    "papermill": {
     "duration": 0.026314,
     "end_time": "2025-02-11T18:30:55.772502",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.746188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pseudolabels\n",
    "# drop fold column\n",
    "train = train.drop(columns=['fold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3b9bd",
   "metadata": {
    "papermill": {
     "duration": 0.010926,
     "end_time": "2025-02-11T18:30:55.795231",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.784305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baebd76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.823462Z",
     "iopub.status.busy": "2025-02-11T18:30:55.823197Z",
     "iopub.status.idle": "2025-02-11T18:30:55.928754Z",
     "shell.execute_reply": "2025-02-11T18:30:55.927681Z"
    },
    "papermill": {
     "duration": 0.121404,
     "end_time": "2025-02-11T18:30:55.930488",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.809084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    17247\n",
       "1    17247\n",
       "2    17246\n",
       "3    17246\n",
       "4    17246\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876923e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:55.964794Z",
     "iopub.status.busy": "2025-02-11T18:30:55.964573Z",
     "iopub.status.idle": "2025-02-11T18:30:55.969033Z",
     "shell.execute_reply": "2025-02-11T18:30:55.968059Z"
    },
    "papermill": {
     "duration": 0.021731,
     "end_time": "2025-02-11T18:30:55.970160",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.948429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    display(train.groupby('fold').size())\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c686e",
   "metadata": {
    "papermill": {
     "duration": 0.015539,
     "end_time": "2025-02-11T18:30:56.000416",
     "exception": false,
     "start_time": "2025-02-11T18:30:55.984877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7ad5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:30:56.026348Z",
     "iopub.status.busy": "2025-02-11T18:30:56.026169Z",
     "iopub.status.idle": "2025-02-11T18:31:14.047842Z",
     "shell.execute_reply": "2025-02-11T18:31:14.046865Z"
    },
    "papermill": {
     "duration": 18.036466,
     "end_time": "2025-02-11T18:31:14.049174",
     "exception": false,
     "start_time": "2025-02-11T18:30:56.012708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/42146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 197/42146 [00:00<00:21, 1966.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 481/42146 [00:00<00:16, 2473.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 781/42146 [00:00<00:15, 2712.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1083/42146 [00:00<00:14, 2831.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1373/42146 [00:00<00:14, 2854.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1659/42146 [00:00<00:14, 2844.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 1945/42146 [00:00<00:14, 2849.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2237/42146 [00:00<00:13, 2869.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 2524/42146 [00:00<00:14, 2740.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2800/42146 [00:01<00:14, 2652.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 3067/42146 [00:01<00:15, 2603.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3329/42146 [00:01<00:15, 2465.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3578/42146 [00:01<00:16, 2372.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 3817/42146 [00:01<00:16, 2318.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 4050/42146 [00:01<00:16, 2284.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4279/42146 [00:01<00:16, 2256.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 4505/42146 [00:01<00:16, 2227.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 4728/42146 [00:01<00:16, 2208.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 4949/42146 [00:02<00:16, 2198.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 5177/42146 [00:02<00:16, 2219.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 5415/42146 [00:02<00:16, 2265.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 5653/42146 [00:02<00:15, 2298.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 5896/42146 [00:02<00:15, 2333.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 6136/42146 [00:02<00:15, 2352.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6372/42146 [00:02<00:15, 2348.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 6611/42146 [00:02<00:15, 2357.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 6855/42146 [00:02<00:14, 2381.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 7094/42146 [00:02<00:14, 2380.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 7333/42146 [00:03<00:14, 2379.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7571/42146 [00:03<00:14, 2372.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 7809/42146 [00:03<00:14, 2303.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 8040/42146 [00:03<00:15, 2244.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 8266/42146 [00:03<00:15, 2248.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8492/42146 [00:03<00:15, 2239.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 8717/42146 [00:03<00:14, 2234.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 8952/42146 [00:03<00:14, 2266.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 9179/42146 [00:03<00:14, 2262.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 9412/42146 [00:03<00:14, 2281.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 9647/42146 [00:04<00:14, 2298.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 9881/42146 [00:04<00:13, 2308.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 10116/42146 [00:04<00:13, 2319.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 10352/42146 [00:04<00:13, 2329.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10587/42146 [00:04<00:13, 2333.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 10823/42146 [00:04<00:13, 2340.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 11063/42146 [00:04<00:13, 2355.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 11301/42146 [00:04<00:13, 2361.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 11543/42146 [00:04<00:12, 2378.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11787/42146 [00:04<00:12, 2394.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 12027/42146 [00:05<00:12, 2391.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 12267/42146 [00:05<00:12, 2393.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 12507/42146 [00:05<00:12, 2386.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12746/42146 [00:05<00:12, 2371.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 12984/42146 [00:05<00:12, 2370.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 13222/42146 [00:05<00:12, 2360.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 13459/42146 [00:05<00:12, 2360.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 13696/42146 [00:05<00:12, 2358.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 13936/42146 [00:05<00:11, 2369.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▎      | 14174/42146 [00:05<00:11, 2371.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 14412/42146 [00:06<00:11, 2359.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 14651/42146 [00:06<00:11, 2367.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14888/42146 [00:06<00:11, 2367.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 15125/42146 [00:06<00:11, 2352.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 15361/42146 [00:06<00:11, 2255.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 15591/42146 [00:06<00:11, 2265.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15823/42146 [00:06<00:11, 2281.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 16056/42146 [00:06<00:11, 2295.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▊      | 16287/42146 [00:06<00:11, 2298.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 16518/42146 [00:06<00:11, 2300.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 16749/42146 [00:07<00:11, 2289.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16981/42146 [00:07<00:10, 2296.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 17215/42146 [00:07<00:10, 2308.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 17450/42146 [00:07<00:10, 2319.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 17683/42146 [00:07<00:10, 2319.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 17915/42146 [00:07<00:10, 2316.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 18151/42146 [00:07<00:10, 2328.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▎     | 18384/42146 [00:07<00:10, 2312.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 18616/42146 [00:07<00:10, 2313.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 18848/42146 [00:07<00:10, 2313.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 19080/42146 [00:08<00:10, 2293.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 19310/42146 [00:08<00:09, 2290.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 19542/42146 [00:08<00:09, 2297.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 19772/42146 [00:08<00:09, 2292.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 20002/42146 [00:08<00:09, 2293.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 20234/42146 [00:08<00:09, 2300.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 20480/42146 [00:08<00:09, 2346.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 20731/42146 [00:08<00:08, 2395.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 20977/42146 [00:08<00:08, 2412.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 21224/42146 [00:08<00:08, 2428.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 21470/42146 [00:09<00:08, 2436.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 21715/42146 [00:09<00:08, 2439.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 21965/42146 [00:09<00:08, 2454.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 22211/42146 [00:09<00:08, 2452.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 22457/42146 [00:09<00:08, 2452.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 22704/42146 [00:09<00:07, 2455.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 22950/42146 [00:09<00:07, 2449.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 23196/42146 [00:09<00:07, 2451.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 23442/42146 [00:09<00:07, 2430.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 23690/42146 [00:09<00:07, 2443.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 23936/42146 [00:10<00:07, 2448.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 24190/42146 [00:10<00:07, 2472.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 24446/42146 [00:10<00:07, 2498.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 24703/42146 [00:10<00:06, 2518.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 24958/42146 [00:10<00:06, 2527.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 25218/42146 [00:10<00:06, 2548.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 25474/42146 [00:10<00:06, 2551.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 25741/42146 [00:10<00:06, 2584.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 26000/42146 [00:10<00:06, 2569.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 26263/42146 [00:10<00:06, 2585.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 26522/42146 [00:11<00:06, 2544.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 26777/42146 [00:11<00:06, 2506.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 27028/42146 [00:11<00:06, 2485.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 27277/42146 [00:11<00:06, 2449.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 27525/42146 [00:11<00:05, 2456.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 27772/42146 [00:11<00:05, 2460.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▋   | 28022/42146 [00:11<00:05, 2471.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 28270/42146 [00:11<00:05, 2428.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 28514/42146 [00:11<00:05, 2411.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 28756/42146 [00:12<00:05, 2363.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 28993/42146 [00:12<00:05, 2284.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 29222/42146 [00:12<00:05, 2257.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 29449/42146 [00:12<00:05, 2248.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 29677/42146 [00:12<00:05, 2255.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 29903/42146 [00:12<00:05, 2239.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 30128/42146 [00:12<00:05, 2205.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 30349/42146 [00:12<00:05, 2186.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 30569/42146 [00:12<00:05, 2189.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 30791/42146 [00:12<00:05, 2196.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 31011/42146 [00:13<00:05, 2142.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 31226/42146 [00:13<00:05, 2142.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 31441/42146 [00:13<00:05, 2139.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 31662/42146 [00:13<00:04, 2159.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 31890/42146 [00:13<00:04, 2194.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 32116/42146 [00:13<00:04, 2211.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 32338/42146 [00:13<00:04, 2195.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 32558/42146 [00:13<00:04, 2193.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 32778/42146 [00:13<00:04, 2164.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 32995/42146 [00:13<00:04, 2140.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 33210/42146 [00:14<00:04, 2104.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 33421/42146 [00:14<00:04, 2081.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 33630/42146 [00:14<00:04, 2083.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 33839/42146 [00:14<00:04, 2069.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 34050/42146 [00:14<00:03, 2080.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 34262/42146 [00:14<00:03, 2091.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 34472/42146 [00:14<00:03, 2084.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 34686/42146 [00:14<00:03, 2098.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 34898/42146 [00:14<00:03, 2102.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 35110/42146 [00:14<00:03, 2107.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 35323/42146 [00:15<00:03, 2113.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 35535/42146 [00:15<00:03, 2100.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 35747/42146 [00:15<00:03, 2104.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 35958/42146 [00:15<00:02, 2100.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 36169/42146 [00:15<00:02, 2096.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 36380/42146 [00:15<00:02, 2100.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 36591/42146 [00:15<00:02, 2099.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 36808/42146 [00:15<00:02, 2120.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 37025/42146 [00:15<00:02, 2133.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 37278/42146 [00:15<00:02, 2250.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 37537/42146 [00:16<00:01, 2351.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 37783/42146 [00:16<00:01, 2383.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 38031/42146 [00:16<00:01, 2410.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 38273/42146 [00:16<00:01, 2404.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 38518/42146 [00:16<00:01, 2416.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 38760/42146 [00:16<00:01, 2411.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 39007/42146 [00:16<00:01, 2426.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 39253/42146 [00:16<00:01, 2434.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 39497/42146 [00:16<00:01, 2433.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 39748/42146 [00:16<00:00, 2454.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 40007/42146 [00:17<00:00, 2493.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 40257/42146 [00:17<00:00, 2470.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 40505/42146 [00:17<00:00, 2461.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 40752/42146 [00:17<00:00, 2450.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 40998/42146 [00:17<00:00, 2441.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 41243/42146 [00:17<00:00, 2421.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 41488/42146 [00:17<00:00, 2426.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 41731/42146 [00:17<00:00, 2420.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 41974/42146 [00:17<00:00, 2407.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 42146/42146 [00:17<00:00, 2343.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pn_history max(lengths): 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 143/143 [00:00<00:00, 15479.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_text max(lengths): 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_len: 354\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "for text_col in ['pn_history']:\n",
    "    pn_history_lengths = []\n",
    "    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        pn_history_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n",
    "\n",
    "for text_col in ['feature_text']:\n",
    "    features_lengths = []\n",
    "    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        features_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n",
    "\n",
    "CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a99f84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.098120Z",
     "iopub.status.busy": "2025-02-11T18:31:14.097879Z",
     "iopub.status.idle": "2025-02-11T18:31:14.111986Z",
     "shell.execute_reply": "2025-02-11T18:31:14.110982Z"
    },
    "papermill": {
     "duration": 0.039951,
     "end_time": "2025-02-11T18:31:14.113538",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.073587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text, feature_text):\n",
    "\n",
    "    # Omit token_type_ids for ModernBERT\n",
    "    is_token_type_ids = CFG.model != 'answerdotai/ModernBERT-base'\n",
    "\n",
    "    inputs = cfg.tokenizer(text, feature_text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False,\n",
    "                           return_token_type_ids=is_token_type_ids)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation_length, location_list):\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "    if annotation_length != 0:\n",
    "        for location in location_list:\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start_idx = -1\n",
    "                end_idx = -1\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                for idx in range(len(offset_mapping)):\n",
    "                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                        start_idx = idx - 1\n",
    "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                        end_idx = idx + 1\n",
    "                if start_idx == -1:\n",
    "                    start_idx = end_idx\n",
    "                if (start_idx != -1) & (end_idx != -1):\n",
    "                    label[start_idx:end_idx] = 1\n",
    "    return torch.tensor(label, dtype=torch.bfloat16)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.feature_texts = df['feature_text'].values\n",
    "        self.pn_historys = df['pn_history'].values\n",
    "        self.annotation_lengths = df['annotation_length'].values\n",
    "        self.locations = df['location'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.pn_historys[item], \n",
    "                               self.feature_texts[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.pn_historys[item], \n",
    "                             self.annotation_lengths[item], \n",
    "                             self.locations[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1ad37",
   "metadata": {
    "papermill": {
     "duration": 0.022796,
     "end_time": "2025-02-11T18:31:14.159179",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.136383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb5bbdc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.207761Z",
     "iopub.status.busy": "2025-02-11T18:31:14.207469Z",
     "iopub.status.idle": "2025-02-11T18:31:14.219135Z",
     "shell.execute_reply": "2025-02-11T18:31:14.218243Z"
    },
    "papermill": {
     "duration": 0.037573,
     "end_time": "2025-02-11T18:31:14.220502",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.182929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        # Debugging input shapes and types\n",
    "        #print(\"Feature extraction inputs:\")\n",
    "        #for k, v in inputs.items():\n",
    "            #print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "        \n",
    "        # Process the inputs through the model\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Debugging the output of the model\n",
    "        #print(f\"Last hidden states: shape={last_hidden_states.shape}, dtype={last_hidden_states.dtype}\")\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Debugging the forward pass\n",
    "        #print(\"Starting forward pass...\")\n",
    "        #print(\"Input keys and shapes:\")\n",
    "        #for k, v in inputs.items():\n",
    "            #print(f\"{k}: shape={v.shape}, dtype={v.dtype}, device={v.device}\")\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16):  # Enable AMP\n",
    "            #print(\"Running model under AMP...\")\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Debugging model output\n",
    "        #print(\"Model outputs:\")\n",
    "        #if isinstance(outputs, tuple):\n",
    "           # for idx, output in enumerate(outputs):\n",
    "                #print(f\"Output {idx}: shape={output.shape if hasattr(output, 'shape') else 'N/A'}\")\n",
    "        #else:\n",
    "            #print(f\"Outputs: {outputs}\")\n",
    "            #pass\n",
    "        \n",
    "        # Final linear layer\n",
    "        feature = outputs.last_hidden_state\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        \n",
    "        # Debugging final output\n",
    "        #print(f\"Final output shape: {output.shape}, dtype={output.dtype}\")\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477729f6",
   "metadata": {
    "papermill": {
     "duration": 0.024941,
     "end_time": "2025-02-11T18:31:14.268539",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.243598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20a80347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.310133Z",
     "iopub.status.busy": "2025-02-11T18:31:14.309778Z",
     "iopub.status.idle": "2025-02-11T18:31:14.320889Z",
     "shell.execute_reply": "2025-02-11T18:31:14.320186Z"
    },
    "papermill": {
     "duration": 0.03459,
     "end_time": "2025-02-11T18:31:14.322312",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.287722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x717b540fe9d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8973e0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.365428Z",
     "iopub.status.busy": "2025-02-11T18:31:14.365161Z",
     "iopub.status.idle": "2025-02-11T18:31:14.381560Z",
     "shell.execute_reply": "2025-02-11T18:31:14.380635Z"
    },
    "papermill": {
     "duration": 0.038919,
     "end_time": "2025-02-11T18:31:14.383104",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.344185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    Validation function with detailed debugging for intermediate outputs.\n",
    "    \"\"\"\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"Starting validation...\")\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        # Move inputs and labels to the correct device\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)  # Model predictions\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # Store predictions\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Debugging: Log step-wise progress and intermediate outputs\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "            #print(f\"Sample Predictions: {y_preds.sigmoid()[:5].view(-1).tolist()}\")  # Example predictions\n",
    "            #print(f\"Sample Labels: {labels[:5].view(-1).tolist()}\")  # Example labels\n",
    "\n",
    "    predictions = np.concatenate(preds)\n",
    "\n",
    "    # Debugging: Check shape and content of predictions\n",
    "    #print(f\"Validation Predictions Shape: {predictions.shape}\")\n",
    "    # print(f\"First 5 Predictions: {predictions[:5]}\")\n",
    "\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"\n",
    "    Training function with detailed debugging for loss and gradients.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting training epoch {epoch + 1} for fold {fold}\")\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the correct device\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        # Mixed precision training\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex, dtype=torch.bfloat16):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "            loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "\n",
    "        # Gradient accumulation\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print(f'Epoch: [{epoch+1}][{step}/{len(train_loader)}] '\n",
    "                  f'Elapsed {timeSince(start, float(step+1)/len(train_loader))} '\n",
    "                  f'Loss: {losses.val:.4f}({losses.avg:.4f}) '\n",
    "                  f'Grad Norm: {grad_norm:.4f}  '\n",
    "                  f'LR: {scheduler.get_lr()[0]}')\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed. Average loss: {losses.avg:.4f}\")\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55fece0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.461639Z",
     "iopub.status.busy": "2025-02-11T18:31:14.461289Z",
     "iopub.status.idle": "2025-02-11T18:31:14.477648Z",
     "shell.execute_reply": "2025-02-11T18:31:14.476925Z"
    },
    "papermill": {
     "duration": 0.070165,
     "end_time": "2025-02-11T18:31:14.479228",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.409063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['pn_history'].values\n",
    "    valid_labels = create_labels_for_scoring(valid_folds)\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "\n",
    "    checkpoint_path = f\"/workspace/deberta-v3-large-5-folds-public/deberta-v3-large_fold{fold}_best.pth\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        LOGGER.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=\"cuda\", weights_only=False) # need to use weight_only = True for latest pytorch version\n",
    "        model.load_state_dict(checkpoint['model'], strict=False)  # Load model weights\n",
    "        model.to(device)\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "    else:\n",
    "        LOGGER.info(\"No checkpoint found, starting fresh.\")\n",
    "        \n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    best_score = 0.\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        print(\"Starting training\")\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        print(\"Starting evaluation\")\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n",
    "        \n",
    "        # scoring\n",
    "        char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score <= score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "            \n",
    "\n",
    "    #predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             #map_location=torch.device('cpu'))['predictions']\n",
    "    predictions = torch.load(OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'),weights_only=False)['predictions']\n",
    "\n",
    "    \n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ccbdd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:14.520462Z",
     "iopub.status.busy": "2025-02-11T18:31:14.520235Z",
     "iopub.status.idle": "2025-02-11T18:31:15.301847Z",
     "shell.execute_reply": "2025-02-11T18:31:15.300580Z"
    },
    "papermill": {
     "duration": 0.803289,
     "end_time": "2025-02-11T18:31:15.303919",
     "exception": false,
     "start_time": "2025-02-11T18:31:14.500630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    wandb=True\n",
    "    competition='NBME'\n",
    "    _wandb_kernel='zehra'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    #model=\"microsoft/deberta-v3-large\" #\"answerdotai/ModernBERT-base\"\n",
    "    # model=\"/kaggle/input/deberta-v3-large/pytorch/0501/1\" If running on Kaggle\n",
    "    model = \"/workspace/deberta-v3-large\" # running on runpod instance\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.05\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr = 1e-5 #encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size = 10 #batch_size=16\n",
    "    fc_dropout=0.2\n",
    "    max_len=354\n",
    "    weight_decay=0.1 #0.01\n",
    "    gradient_accumulation_steps=1 #1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    CFG.trn_fold = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a47a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:15.346346Z",
     "iopub.status.busy": "2025-02-11T18:31:15.346079Z",
     "iopub.status.idle": "2025-02-11T18:31:15.351235Z",
     "shell.execute_reply": "2025-02-11T18:31:15.350036Z"
    },
    "papermill": {
     "duration": 0.025867,
     "end_time": "2025-02-11T18:31:15.352592",
     "exception": false,
     "start_time": "2025-02-11T18:31:15.326725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef30fb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:15.393083Z",
     "iopub.status.busy": "2025-02-11T18:31:15.392734Z",
     "iopub.status.idle": "2025-02-11T18:31:15.401698Z",
     "shell.execute_reply": "2025-02-11T18:31:15.400626Z"
    },
    "papermill": {
     "duration": 0.030158,
     "end_time": "2025-02-11T18:31:15.403317",
     "exception": false,
     "start_time": "2025-02-11T18:31:15.373159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold_training(oof_df, fold):\n",
    "    \"\"\"\n",
    "    Helper function to run training for a specific fold.\n",
    "    Concatenates the out-of-fold predictions to oof_df.\n",
    "    \"\"\"\n",
    "    _oof_df = train_loop(train, fold)\n",
    "    oof_df = pd.concat([oof_df, _oof_df])\n",
    "    LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "    evaluate_results(_oof_df)  # Evaluate results after each fold\n",
    "    return oof_df\n",
    "\n",
    "def evaluate_results(oof_df):\n",
    "    \"\"\"\n",
    "    Function to handle the result evaluation, including scoring and logging.\n",
    "    \"\"\"\n",
    "    labels = create_labels_for_scoring(oof_df)\n",
    "    predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
    "    char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
    "    results = get_results(char_probs, th=0.5)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15fb9553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T18:31:15.447814Z",
     "iopub.status.busy": "2025-02-11T18:31:15.446632Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-02-11T18:31:15.427855",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /workspace/deberta-v3-large-5-folds-public/deberta-v3-large_fold0_best.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "\n",
      "Starting training epoch 1 for fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/6898] Elapsed 0m 2s (remain 277m 11s) Loss: 0.0122(0.0122) Grad Norm: 86621.5469  LR: 9.999999999675951e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/6898] Elapsed 2m 0s (remain 135m 17s) Loss: 0.0072(0.0063) Grad Norm: 41214.7656  LR: 9.99999669437843e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][200/6898] Elapsed 5m 27s (remain 181m 37s) Loss: 0.0105(0.0061) Grad Norm: 18489.2773  LR: 9.999986908109645e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][300/6898] Elapsed 8m 54s (remain 195m 25s) Loss: 0.0019(0.0059) Grad Norm: 8818.4082  LR: 9.999970640882282e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][400/6898] Elapsed 12m 23s (remain 200m 42s) Loss: 0.0017(0.0058) Grad Norm: 14749.0674  LR: 9.999947892717426e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][500/6898] Elapsed 15m 50s (remain 202m 11s) Loss: 0.0050(0.0056) Grad Norm: 11383.1670  LR: 9.999918663644563e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][600/6898] Elapsed 19m 16s (remain 201m 54s) Loss: 0.0008(0.0055) Grad Norm: 2717.6829  LR: 9.999882953701581e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][700/6898] Elapsed 22m 44s (remain 201m 2s) Loss: 0.0048(0.0053) Grad Norm: 53704.6133  LR: 9.999840762934764e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][800/6898] Elapsed 26m 12s (remain 199m 25s) Loss: 0.0015(0.0052) Grad Norm: 27202.2148  LR: 9.999792091398804e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][900/6898] Elapsed 29m 39s (remain 197m 23s) Loss: 0.0547(0.0053) Grad Norm: 58664.6797  LR: 9.999736939156785e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1000/6898] Elapsed 33m 6s (remain 195m 3s) Loss: 0.0088(0.0053) Grad Norm: 21805.4766  LR: 9.999675306280197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1100/6898] Elapsed 36m 35s (remain 192m 40s) Loss: 0.0039(0.0052) Grad Norm: 15249.6924  LR: 9.999607192848925e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1200/6898] Elapsed 40m 3s (remain 190m 0s) Loss: 0.0108(0.0051) Grad Norm: 45413.6055  LR: 9.999532598951263e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1300/6898] Elapsed 43m 30s (remain 187m 10s) Loss: 0.0000(0.0050) Grad Norm: 50.2443  LR: 9.999451524683896e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1400/6898] Elapsed 46m 58s (remain 184m 17s) Loss: 0.0019(0.0050) Grad Norm: 10048.0176  LR: 9.99936397015191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1500/6898] Elapsed 50m 25s (remain 181m 17s) Loss: 0.0018(0.0049) Grad Norm: 17036.7109  LR: 9.999269935468797e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1600/6898] Elapsed 53m 52s (remain 178m 16s) Loss: 0.0001(0.0049) Grad Norm: 295.9210  LR: 9.999169420756443e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1700/6898] Elapsed 57m 20s (remain 175m 10s) Loss: 0.0004(0.0049) Grad Norm: 3862.3428  LR: 9.999062426145132e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1800/6898] Elapsed 60m 46s (remain 172m 0s) Loss: 0.0110(0.0048) Grad Norm: 87798.3203  LR: 9.998948951773553e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1900/6898] Elapsed 64m 13s (remain 168m 50s) Loss: 0.0001(0.0048) Grad Norm: 1733.2506  LR: 9.99882899778879e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2000/6898] Elapsed 67m 41s (remain 165m 40s) Loss: 0.0077(0.0047) Grad Norm: 53345.4414  LR: 9.998702564346325e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2100/6898] Elapsed 71m 10s (remain 162m 31s) Loss: 0.0008(0.0047) Grad Norm: 11223.8828  LR: 9.998569651610042e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2200/6898] Elapsed 74m 38s (remain 159m 17s) Loss: 0.0217(0.0047) Grad Norm: 173212.4062  LR: 9.998430259752222e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2300/6898] Elapsed 78m 6s (remain 156m 1s) Loss: 0.0001(0.0046) Grad Norm: 1280.6219  LR: 9.998284388953545e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2400/6898] Elapsed 81m 34s (remain 152m 47s) Loss: 0.0022(0.0046) Grad Norm: 45547.7148  LR: 9.998132039403086e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2500/6898] Elapsed 85m 2s (remain 149m 31s) Loss: 0.0131(0.0045) Grad Norm: 153785.6562  LR: 9.997973211298323e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2600/6898] Elapsed 88m 31s (remain 146m 15s) Loss: 0.0049(0.0046) Grad Norm: 33719.5703  LR: 9.997807904845123e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2700/6898] Elapsed 91m 59s (remain 142m 56s) Loss: 0.0053(0.0045) Grad Norm: 34434.7734  LR: 9.997636120257758e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2800/6898] Elapsed 95m 27s (remain 139m 37s) Loss: 0.0028(0.0045) Grad Norm: 25234.0059  LR: 9.997457857758896e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2900/6898] Elapsed 98m 55s (remain 136m 17s) Loss: 0.0086(0.0045) Grad Norm: 26884.9492  LR: 9.997273117579597e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3000/6898] Elapsed 102m 23s (remain 132m 57s) Loss: 0.0017(0.0044) Grad Norm: 27281.7949  LR: 9.997081899959324e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3100/6898] Elapsed 105m 51s (remain 129m 37s) Loss: 0.0046(0.0044) Grad Norm: 26328.7969  LR: 9.996884205145929e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3200/6898] Elapsed 109m 21s (remain 126m 18s) Loss: 0.0002(0.0044) Grad Norm: 4520.5742  LR: 9.996680033395664e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3300/6898] Elapsed 112m 50s (remain 122m 58s) Loss: 0.0001(0.0044) Grad Norm: 2131.8279  LR: 9.996469384973175e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3400/6898] Elapsed 116m 17s (remain 119m 34s) Loss: 0.0093(0.0044) Grad Norm: 32567.0195  LR: 9.996252260151506e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3500/6898] Elapsed 119m 45s (remain 116m 11s) Loss: 0.0013(0.0043) Grad Norm: 14637.7598  LR: 9.996028659212089e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3600/6898] Elapsed 123m 29s (remain 113m 4s) Loss: 0.0151(0.0043) Grad Norm: 136679.4219  LR: 9.995798582444759e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3700/6898] Elapsed 126m 56s (remain 109m 39s) Loss: 0.0094(0.0043) Grad Norm: 64251.7422  LR: 9.995562030147736e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3800/6898] Elapsed 130m 22s (remain 106m 13s) Loss: 0.0029(0.0043) Grad Norm: 21117.6172  LR: 9.995319002627643e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3900/6898] Elapsed 133m 50s (remain 102m 49s) Loss: 0.0023(0.0043) Grad Norm: 99178.1641  LR: 9.995069500199487e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4000/6898] Elapsed 137m 18s (remain 99m 25s) Loss: 0.0014(0.0043) Grad Norm: 36063.9258  LR: 9.994813523186671e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4100/6898] Elapsed 140m 44s (remain 95m 59s) Loss: 0.0001(0.0042) Grad Norm: 2401.2698  LR: 9.994551071920995e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4200/6898] Elapsed 144m 11s (remain 92m 33s) Loss: 0.0016(0.0042) Grad Norm: 44863.3438  LR: 9.994282146742643e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4300/6898] Elapsed 147m 39s (remain 89m 9s) Loss: 0.0006(0.0042) Grad Norm: 49994.0781  LR: 9.994006748000197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4400/6898] Elapsed 151m 6s (remain 85m 44s) Loss: 0.0020(0.0042) Grad Norm: 57971.9570  LR: 9.99372487605063e-06\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    CFG.debug = True\n",
    "\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "\n",
    "        # Run training for a single fold in debug mode or multiple folds otherwise\n",
    "        if CFG.debug:\n",
    "            fold = 0  # In debug mode, we only use fold 0\n",
    "            if fold in CFG.trn_fold:\n",
    "                oof_df = run_fold_training(oof_df, fold)\n",
    "        else:\n",
    "            for fold in range(CFG.n_fold):  # For all folds in non-debug mode\n",
    "                if fold in CFG.trn_fold:\n",
    "                    oof_df = run_fold_training(oof_df, fold)\n",
    "\n",
    "        # Final evaluation and saving results\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        evaluate_results(oof_df)  # Final evaluation of all results\n",
    "        oof_df.to_pickle(OUTPUT_DIR + 'oof_df.pkl')\n",
    "\n",
    "    if CFG.wandb:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a1e8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Reference\n",
    "\n",
    "https://www.kaggle.com/code/yasufuminakama/nbme-deberta-base-baseline-train\n",
    "\n",
    "\n",
    "See the run log on Kaggle: https://www.kaggle.com/code/zehrakorkusuz/training-deberta-v3-large"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3075283,
     "sourceId": 33607,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 49736,
     "modelInstanceId": 35444,
     "sourceId": 42188,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nbme_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/ft-pl.ipynb",
   "output_path": "output.ipynb",
   "parameters": {},
   "start_time": "2025-02-11T18:30:38.269443",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}